Exploring Large Language Model based Intelligent Agents Definitions, Methods, and Prospects
探索基于大型语言模型的智能体：定义、方法与前景
Exploring Large Language Model based Intelligent Agents Definitions, Methods, and Prospects
摘要：智能体被认为是从人工智能通向通用人工智能（AGI）的潜在路径。因此，研究人员为实现智能体投入了大量努力，探索了多种实现方式。得益于近期大型语言模型（LLMs）的进展，以通用自然语言作为接口的基于LLM的智能体在多种应用中展现出强大的泛化能力——从作为自主的通用任务助手，到在编码、社会和经济等领域中的应用，基于LLM的智能体为广泛的探索提供了可能性。本文调研了当前研究现状，深入概述了基于LLM的智能体，包括单智能体系统和多智能体系统，内容涵盖其定义、研究框架和基础组件，例如智能体的构成、认知与规划方法、工具使用以及对环境反馈的响应。我们还深入探讨了在多智能体系统中部署基于LLM的智能体的机制，包括多角色协作、消息传递以及缓解智能体间通信问题的策略。本文讨论还涉及热门数据集和应用场景。最后，我们展望了基于LLM的智能体的未来发展，考虑了人工智能和自然语言处理领域的演变趋势。  关键词：大型语言模型，智能体，多智能体系统  “我们将人工智能定义为研究那些能够从环境中接收感知并执行行动的智能体的学科。” ——《人工智能：现代方法》，斯图尔特·拉塞尔和彼得·诺维格（2003年）。 好的，我将继续翻译论文的下一部分：引言（Introduction），包括其子章节 1.1 智能体（Intelligent Agents）、1.2 基于强化学习的智能体（RL-based Agents） 和 1.3 基于大型语言模型的智能体（LLM-based Agents）。以下是翻译内容：目录- 摘要 - 关键词 - 1 引言 - 1.1 智能体  - 1.2 基于强化学习的智能体  - 1.3 基于大型语言模型的智能体  - 2 概述 - 2.1 单智能体系统  - 2.2 多智能体系统  - 2.3 智能体系统模板  - 3 基于LLM的智能体系统框架 - 3.1 基于LLM的单智能体系统  - 3.1.1 规划  - 3.1.2 记忆  - 3.1.3 反思  - 3.1.4 环境  - 3.1.5 行动  - 3.2 基于LLM的多智能体系统  - 3.2.1 多智能体系统的关系  - 3.2.2 规划类型  - 3.2.3 提升通信效率的方法  - 4 性能评估 - 4.1 数据集  - 4.2 基准  - 5 前景应用 - 5.1 自然科学  - 5.1.1 数学  - 5.1.2 化学与材料  - 5.1.3 生物学  - 5.1.4 气候科学  - 5.2 通用自主智能体  - 5.2.1 通用任务助手  - 5.3 社会科学  - 5.3.1 经济学与金融  - 5.3.2 政治学  - 5.3.3 社会学  - 5.3.4 法律  - 5.3.5 心理学  - 5.3.6 教育  - 5.4 工程系统  - 5.4.1 计算机科学  - 5.4.2 机器人系统  - 5.4.3 电力系统  - 5.4.4 交通系统  - 5.4.5 工业控制系统  - 5.4.6 医疗系统  - 5.4.7 军事系统  - 6 讨论 - 6.1 趋势  - 6.2 挑战  - 6.2.1 大型语言模型的固有约束  - 6.2.2 动态扩展  - 6.2.3 安全与信任  - 7 结论 - 参考文献1 引言1.1 智能体近年来，对基于大型语言模型（LLM）的智能体的研究引起了广泛关注。在人工智能（AI）中，“智能体”这一概念拥有坚实的基础，主要强调人工智能系统中智能体与其环境之间的区别[1]。任何能够感知其环境并采取行动的实体都可以被视为智能体。智能体具有在不同环境中执行任务的自主性，它们依靠过去的经验和知识做出符合预定目标的决策。 通常，智能体表现出以下特征[1,2,3,4]： - 自主性：智能体能够独立感知环境、做出决策并采取行动，而无需依赖外部指令。  - 感知能力：智能体配备了感知能力，通过传感器收集关于环境的信息。  - 决策能力：智能体根据感知到的信息作出决策，选择适当的行动以实现其目标。  - 行动能力：智能体执行的行动会改变环境的状态。  智能体可以分为五种类型：简单反射智能体、基于模型的反射智能体、基于目标的智能体、基于效用的智能体和学习智能体[1]。基于强化学习（RL-based）的智能体和基于大型语言模型（LLM-based）的智能体属于学习智能体类别。 学习智能体的显著特征是它们能够通过经验学习并改进自身行为。这些智能体通过观察环境及其行动的结果，随着时间的推移提升其决策过程。这种改进弥补了其他类型智能体的固有局限性，例如缺乏自主学习能力以及在处理多步骤决策问题时的困难。这些不同类型的智能体通常依赖固定规则或简单模型，这可能限制其适应性和泛化能力[5,6]。1.2 基于强化学习的智能体基于强化学习（RL-based）的智能体的主要目标是学习一种策略，指导智能体在不同状态下采取行动，以最大化累积奖励[7]。这些智能体通过试错学习，不断调整策略以优化长期奖励。基于强化学习的智能体已在多个领域取得显著成功[8]，例如游戏[9]、机器人控制[10]和自动驾驶[11]。 强化学习的基本框架包括智能体、环境、状态、行动和奖励。智能体在环境中执行行动，环境根据智能体的行动反馈状态变化和奖励。智能体基于环境的反馈调整其策略，以在未来的行动中获得更高的累积奖励。  然而，近年来，基于强化学习的智能体的一些局限性逐渐显现，典型局限性包括[12,13]： - 训练时间：强化学习算法通常需要大量时间才能收敛到稳定且令人满意的性能。这是因为智能体必须探索环境，从交互中学习，并根据观察到的奖励不断更新策略。训练时间过长可能成为一个显著的缺点，尤其是在应对大规模和复杂问题时。  - 样本效率：基于强化学习的智能体通常需要在环境中进行多次交互才能学会有效的策略。这种高样本需求可能在计算上成本高昂，并且在某些应用中（如机器人或现实世界场景）不可行，因为数据收集可能昂贵或耗时。  - 稳定性：强化学习的训练过程可能不稳定，特别是在使用高维函数逼近器（如深度神经网络）时。这种不稳定性可能导致性能波动，甚至学习算法发散。在基于强化学习的智能体经常面对非平稳环境（即随着智能体策略演变而动态变化的环境）时，这一问题尤为突出。  - 泛化能力：基于强化学习的智能体往往专注于其训练的特定任务，难以有效泛化到新任务或新环境。这种泛化能力的缺乏可能是一个重大限制，因为它要求为每个新问题从头训练一个新智能体。迁移学习旨在通过利用在一个任务中获得的知识来改进相关但不同任务的学习，从而解决这一问题。然而，为强化学习开发有效的迁移学习技术仍是一个开放的研究挑战。1.3 基于大型语言模型的智能体当代研究凸显了大型语言模型（LLMs）在自然语言处理（NLP）领域的卓越能力，包括推理、通用问答、编程和文本生成[14,15]。然而，研究也揭示了大型语言模型在处理实用任务时经常遇到的诸多障碍[16,17,18]： - 上下文长度限制：大型语言模型常常受限于上下文长度，相较于文本开头或结尾的部分，它们更容易忽略上下文中间的文本。  - 知识更新延迟：大型语言模型在每次训练迭代中需要大量时间和计算资源，导致知识更新滞后。  - 缺乏直接工具使用：大型语言模型无法直接使用外部工具，例如计算器、SQL执行器或代码解释器。  引入智能体机制可以在一定程度上缓解上述挑战。以GPT-4[19]等大型语言模型为基础构建的智能体（LLM-based agents）结合了大型语言模型和智能体的优势。与其他智能体不同，基于LLM的智能体利用大型语言模型进行认知和策略处理，展现智能行为。 相较于其他类型的智能体，基于LLM的智能体的优势包括以下几点[20,21]： - 强大的自然语言处理和全面的知识：大型语言模型利用在海量文本数据上训练获得的强大语言理解和生成能力，具备丰富的常识知识、特定领域的专业知识和事实数据。这使得基于LLM的智能体能够处理各种自然语言任务。  - 零样本或少样本学习：大型语言模型在训练期间已获得大量知识和技能，因此基于LLM的智能体通常只需要很少的样本就能在新的任务中表现出色。其卓越的泛化能力使它们在未曾遇到的情况下也能表现优异。- 自然的人机交互：基于LLM的智能体能够理解并生成自然语言文本，促进人类用户与智能体通过自然语言进行交互。这增强了人机交互的便利性和以用户为中心的设计。  
 图1：智能体发展的路线图（注释：“LMM-based agent”指的是基于大型多模态模型的智能体（Large Multimodal Model-based Agent）。）通过结合大型语言模型的语言理解和生成能力与智能体的决策和规划能力，基于LLM的智能体为解决大型语言模型在实用应用中面临的问题提供了有前景的解决方案。 本文从第2节对基于LLM的智能体系统进行介绍开始，随后在第3节概述基于LLM的智能体系统的框架。第4节描述了智能体的常见数据集和评估方法。第5节探讨了基于LLM的智能体在自然科学、社会科学、工程系统和通用领域的应用。最后，第6节探讨了智能体的发展轨迹，包括增强基于LLM的智能体的适应能力，整合多模态模型或大型多模态模型（LMMs）以赋予智能体多模态信息处理能力，并应对所面临的挑战。2 概述在详细分析基于大型语言模型（LLM）的智能体时，它们可以被分为两大主要类别：单智能体系统和多智能体系统。这两种不同的系统类型在应用领域、记忆与反思机制、数据需求、模态以及工具集等方面表现出显著差异。本文接下来将深入探讨这些智能体类型，以帮助读者理解它们的独特属性和应用范围。2.1 单智能体系统单智能体系统包含一个基于大型语言模型的智能体，该智能体能够处理多种任务和领域，通常被称为基于LLM的智能体。基于LLM的智能体通常具备广泛的语言理解与生成能力，以及多任务泛化能力，使其能够执行诸如代码生成、游戏探索和数据管理等任务。此外，不同基于LLM的智能体的评估方法各异，使用的工具也未标准化。根据设计目标的不同，基于LLM的智能体可能是单模态或多模态的。即将推出的表1将提供当前几种基于LLM的智能体的概要。  
 图2：基于LLM的智能体概览（注释：输入：目标（O）和环境观察输入到LLM（L）。处理：LLM结合记忆（M）进行规划，生成行动（A）。执行：行动作用于环境或调用工具，产生结果。反馈：环境返回反馈，智能体通过反思（R）更新记忆并优化后续行动。循环：流程重复，直到目标达成。）每个基于LLM的智能体 V  可以简洁地表示为一个五元组 V = (L, O,M, A, R)，其中：- L（LLM）：表示大型语言模型及其智能体的配置和能力，通常需要定义提示（prompt）或使用特定领域的专用LLM。可以假设大型语言模型无需额外训练，但其推理参数（如温度）可以动态调整。大型语言模型作为基于LLM的智能体的“大脑核心”，负责根据当前观察、历史记忆和奖励信息进行任务规划和决策。  - O（目标，Objective）：表示智能体必须实现的主要目标，即终止状态或条件。智能体需要根据目标进行任务分解和规划。  - M（记忆，Memory）：智能体的记忆存储信息并代表智能体的当前状态。当智能体采取行动时，来自环境的后续反馈和奖励信息会被记录在记忆中。  - A（行动，Action）：智能体拥有一系列可执行的行动，通常包括使用各种工具、设计新工具或向环境或其他智能体发送消息。  - R（反思，Rethink）：在执行行动后，智能体需要利用其反思能力（称为“Rethink”），对之前的行动及相关的环境反馈奖励进行反思。这一反思过程应与智能体的记忆、大型语言模型或其他适当模型结合，以规划并执行后续行动。  关于基于LLM的智能体的外部组件，环境（Environment）和工具（Tool）通常包括以下内容： - 工具（Tool）：指智能体可以使用的任何工具，例如计算器、代码解释器、机器人手臂等。  - 环境（Environment）：智能体所处的环境对其行动有显著影响。智能体可以观察并与该环境交互，获取有价值的反馈。  2.2 多智能体系统与单智能体系统不同，多智能体系统（MAS）是由多个相互交互的智能体组成的计算机系统[22]。受明斯基的“心智社会”（Society of Mind，SOM）[23]和基于自然语言的心智社会（NLSOM）[24]的启发，多智能体系统（MAS）的设计需要在多个智能体之间实现更高水平的复杂协调，尤其是在它们之间的交互和信息共享方面。每个智能体通常具有特定领域的专业知识，这使得多智能体系统在跨多个领域的任务中尤为有利。 Decker [25] 为多智能体系统提出了一个四维框架。这些维度包括： 1) 智能体的粒度（Granularity of Agents）：从粗粒度到精细配置；  2) 智能体知识的异质性（Heterogeneity in Agent Knowledge）：比较具有冗余知识的智能体与具有专业知识的智能体；  3) 控制分布机制（Mechanisms for the Distribution of Control）：可以分为友善型或竞争型、团队导向或层次结构型，并且可能涉及静态或动态的角色分配；  4) 通信协议类型（Varieties of Communication Protocols）：区分黑板系统和基于消息的系统，并指定从低级到高级内容的分级。  从应用角度来看，Parunak [26] 从三个重要特征提出了多智能体系统的分类： - 系统功能（System Function）；  - 系统架构（System Architecture，例如通信、协议、人类参与）；  - 智能体架构（Agent Architecture，例如异质性程度、反应式与深思熟虑式）。  这一分类的主要贡献在于将多智能体系统分为智能体层面和系统层面的特征。 Stone 和 Veloso [2] 根据两个关键维度对多智能体系统进行了分类：异质性程度和通信程度。这一分类框架产生了四种典型的多智能体系统：同质非通信智能体、异质非通信智能体、同质通信智能体和异质通信智能体。通常采用诸如控制理论和强化学习等方法，为这些智能体赋予智能和自主性。  正如 Yang [27] 所强调，在单智能体范式中深度 Q 学习（DQN）[8] 架构取得突破后，2019 年见证了基于强化学习的智能体向多智能体系统的扩展，标志着多智能体强化学习（MARL）技术的蓬勃发展。在多智能体强化学习的背景下，Hu 等人 [28] 提供了一种分类方法，通过以下四个维度区分多智能体强化学习算法： - 任务模式（Task Mode）：合作型或竞争型；  - 智能体类型（Agents Type）：异质或同质；  - 学习风格（Learning Style）：独立学习、集中式训练分散式执行（CTDE）或完全集中式；  - 知识共享（Knowledge Sharing）：智能体层面、场景层面或任务层面。  自 2022 年以来，大型语言模型蓬勃发展。考虑基于LLM的智能体在多智能体系统中的应用，可以用图 G(V, E) 表示多个基于LLM的智能体之间的关系，其中 V 是节点集合，V_i  表示一个基于LLM的智能体， E 是边集合， E_{ij}  表示基于LLM的智能体V_i 和  V_j  之间的消息传递和关系。我们提出了一个分类方法，考虑以下方面： - 多角色协调（Multi-Role Coordination）：合作型、竞争型、混合型和层次型；  - 规划类型（Planning Type）：集中式规划分散式执行（CPDE）和分散式规划分散式执行（DPDE）。  

 图3：基于LLM的智能体之间的关系详细的基于LLM的智能体信息将在接下来的表2中列出。2.3 智能体系统模板许多研究人员提出了智能体和模板解决方案，以帮助未来的研究者和爱好者开发更相关的智能体。例如，ToolLLM [74] 提供了一个全面的模板，用于数据构建、模型训练和评估，促进了功能更强的智能体的开发。 多个项目，如 AutoGPT [75]、XLang [76]、LangChain [77]、MiniAGI [76]、XAgent [78]、OpenAgents [79] 和 WorkGPT [80]，已在 GitHub 上开源了其代码。这些模板支持多种功能，涵盖不同的思维、规划和审查方法，并允许将各种模型集成作为智能体的核心组件。此外，AgentGPT [81] 提供了微调模型和将本地数据纳入模型训练过程的功能。Crouse 等人 [82] 引入了一个简化的模板，利用线性时序逻辑（Linear Temporal Logic，LTL）来促进基于LLM的智能体的设计和实现，推动快速实验并增强智能体性能。 此外，AutoGen [83]、AgentVerse [84]、AutoAgents [85] 和 AGENTS [86] 等模板通过允许在多智能体配置中选择和定制角色，加速了多智能体系统的创建，从而简化了开发过程。
3 基于LLM的智能体系统框架3.1 基于LLM的单智能体系统本节将单智能体系统简要分解为五个关键组成部分：规划（Planning）、记忆（Memory）、反思（Rethinking）、环境（Environment）和行动（Action）。每个组成部分因其独特的贡献而被突出显示，共同构成了系统的整体，体现了其复杂的设计和功能。3.1.1 规划规划能力定义了基于LLM的智能体根据既定目标和现有环境约束制定行动序列的能力，以确保目标实现。这是基于LLM的智能体的重要特征，涵盖任务分析、潜在行动预测、最优行动选择以及处理复杂问题和任务的能力。与使用诸如Dijkstra算法[87]和POMDP[88]等规划算法在状态空间中寻找最佳行动序列并在不确定环境中进行规划的传统智能体和基于强化学习的智能体不同，基于强化学习的智能体需要学习策略[5]。基于LLM的智能体的规划能力主要来源于大型语言模型。尽管大型语言模型主要通过自然语言或特定文本进行通信，但其内部结构和训练方法赋予了它们一定程度的规划能力。近期研究趋势还强调，引导大型语言模型进行思考和规划是其发展的关键方向。 
 图4：规划能力的类型上下文学习（In-Context Learning, ICL）方法 上下文学习（ICL）利用自然语言提示（包括任务描述并可能辅以任务示例）来指导语言模型解决问题[106]。思维链（Chain of Thought, CoT），包括复杂CoT[90]、自动CoT[91]和零样本CoT[92]，通过思维引导提示系统地将复杂任务分解为较小的、可管理的部分，从而促进长期规划和推理。为了提升CoT的效果，自一致性（Self-consistency）[93]利用大型语言模型生成多个推理路径并整合结果，例如通过在路径中投票选择最一致的答案。思维树（Tree of Thought, ToT）[94]将问题分成几个思维阶段，在每个阶段生成多个概念，形成树状结构。搜索过程采用广度优先或深度优先探索，并使用分类器或多数投票评估每个状态。 为了增强CoT的泛化能力，最少到最多（Least-to-Most）[95]将复杂问题分解为子问题并按顺序解决。同时，思维框架（Skeleton of Thought, SoT）[96]首先指导大型语言模型生成答案的框架，随后通过API调用或批量解码完成每个框架点，大幅加快答案生成速度。思维图（Graph of Thought, GoT）[97]将大型语言模型生成的信息表示为任意图，其中信息单元（LLM的思维）作为顶点，顶点之间的依赖关系作为边。渐进提示（Progressive Hint Prompting, PHP）[98]通过使用先前生成的响应作为提示，加速引导模型得出准确答案，从而提升模型在问题解决中的推理能力。自优化（Self-Refine）[107]使大型语言模型对其输出提供多方面的反馈，并根据该反馈迭代优化先前输出，模拟人类在生成文本时可能经历的迭代改进过程。 外部能力方法 使用外部能力方法涉及在计算机科学中运用工具、算法或仿真技术进行规划。LLM+P[100]依赖经典规划器进行长期规划，使用规划领域定义语言（Planning Domain Definition Language, PDDL）[108]作为中间接口。模型将问题翻译为问题描述（problem PDDL），请求规划器根据“领域PDDL”（Domain PDDL）生成PDDL计划，然后将PDDL计划转回自然语言。LLM-DP[101]将大型语言模型与符号规划器结合，用于解决具身任务，利用大型语言模型对环境中行动影响的理解和规划器的高效求解能力。Guan等人[109]利用GPT-4生成PDDL，通过自然语言反馈优化PDDL，并将提取的领域模型应用于多种方法的稳健规划。RAP[102]框架通过添加世界模型在大型语言模型中实现有意识的规划推理，采用原则性规划（特别是蒙特卡洛树搜索）进行高效探索，生成高回报的推理轨迹。 除了这些方法外，还提出了其他几种方法来增强规划和推理能力。Zhao等人[110]将大型语言模型用作常识世界模型，并应用启发式策略解决复杂任务规划问题。Romero等人[103]概述了一种将认知架构与大型语言模型整合的可行方法。Merkle和Mikut[104]提出了基于仿真的方法，通过知识图和实体嵌入表示异构上下文，并通过并行运行的智能体动态组合策略。FaR[111]结合心智理论（Theory of Mind, ToM）[112]提供了一个框架，使大型语言模型能够预测未来挑战并思考潜在行动。LATS[113]将大型语言模型作为智能体、价值函数和优化器，充分利用其潜在优势增强规划、行动和推理能力。Think-on-Graph[114]通过在知识图上执行束搜索，帮助智能体识别最优规划路径。这些方法展示了大型语言模型在各种规划和推理任务中的多功能性和潜力，为未来更先进、更高效的解决方案铺平了道路。 多阶段方法 多阶段方法将规划过程分解为不同阶段，旨在提升大型语言模型在复杂推理和问题解决任务中的性能。SwiftSage[105]是一个受双过程理论启发的框架，结合了行为克隆和引导型大型语言模型的优点，以提升任务完成性能和效率。它包括两个主要模块：SWIFT模块负责快速、直观的思考，SAGE模块处理深思熟虑的思考。DECKARD[48]的探索过程分为梦想（Dreaming）和清醒（Awake）两个阶段。在梦想阶段，智能体利用大型语言模型将任务分解为子目标。在清醒阶段，智能体为每个子目标学习模块化策略，根据智能体的经验验证或纠正假设。 这些方法增强了模型在复杂推理和问题解决任务中的性能。通过这些方法，可以引导大型语言模型进行思考和规划，以应对复杂的问题和任务。3.1.2 记忆基于LLM的智能体中记忆系统的主要功能是保存和管理知识、经验数据和历史信息，这些信息可在解决问题和执行任务时供参考和修改。此外，记忆常常体现智能体的当前状态。通常，此类智能体的记忆以文本形式记录，便于与大型语言模型无缝交互。本文概述了常见的记忆分类及其相关设计方法。 

 图5：记忆的类型短期记忆（Short-term Memory） 短期记忆存储并操作有限量的瞬时信息。在基于LLM的智能体中，这可以通过将输入文本与当前任务相关的上下文数据结合来实现，受限于大型语言模型的上下文长度。如ChatDev[66]所示，对话历史被存档，使智能体能够根据记录的智能体间通信决定后续步骤。LangChain[77]通过封装每次交互的关键信息并保留最频繁的交互来提升短期记忆的效率。 长期记忆（Long-term Memory） 长期记忆存储和管理大量知识、经验数据和历史记录。使用长期记忆的智能体可能涉及与外部知识库、数据库或其他信息源的交互。外部记忆的设计可以利用知识图[115]、向量数据库[116]、关系数据库查询或API调用等技术与外部数据源交互。Voyager[50]采用不断扩展的技能库来存储和检索复杂行为。在GITM[51]中，记忆主要用于从外部知识库中提取最相关的文本知识，长期记忆随后利用这些知识识别所需材料、工具和相关信息。为了提升智能体性能，ExpeL[117]智能体跨多个任务保存经验。在Reflexion[118]中，通过自我反思获得的经验被保存在长期记忆中，并影响未来行动。MemGPT[119]是一个智能系统，能够管理不同的记忆层级，有效地在大型语言模型有限的上下文窗口内提供扩展上下文，并利用中断来管理与用户之间的控制流。短期记忆可以封装并概括关键信息，然后动态存储到长期记忆中。如Generative Agents[63]所示，智能体通过存档和更新其经验维持其内部状态，通过将其经验与大型语言模型的语言表示对齐生成自然语言，并持续积累新经验并将其与现有经验整合。智能体的记忆随时间演变，并可动态访问以表示智能体的当前状态。 记忆检索（Memory Retrieval） 检索增强生成（Retrieval-augmented generation）[120]可以将信息检索组件与大型语言模型结合，产生更可靠的输出。检索目标可以用记忆表示，即知识库。记忆检索对于高效访问和管理记忆至关重要。在基于LLM的智能体中，记忆检索可以通过在线学习和自适应调整来实现。在制定记忆检索方法时，可以采用在线强化学习、多任务学习或注意力机制等技术，实现模型参数的实时更新和调整。LaGR-SEQ[121]引入了SEQ（样本高效查询，Sample Efficient Query），训练一个次级基于强化学习的智能体来决定何时查询大型语言模型以获得解决方案。REMEMBER[54]为大型语言模型配备长期记忆，使其能够从过去经验中汲取经验，并引入强化学习和经验记忆来更新记忆。Synapse[122]从原始状态中清除与任务无关的信息，使在有限上下文中可以容纳更多样本。它通过存储样本嵌入并通过相似性搜索检索它们来泛化到新任务。Kang等人[123]讨论了人类大脑中分布式记忆存储的特性，提出了构建内部记忆模块DT-Mem，允许智能体存储和检索与各种下游任务相关的信息。Wang等人[124]利用多模型记忆存储智能体收集的交互经验，并使用具身RAG（Retrieval-Augmented Generation）使智能体通过探索开放世界的Minecraft实现自我改进。 通过上述方法，可以为基于LLM的智能体设计适合的记忆类型和检索技术。需要强调的是，基于LLM的智能体可以同时包含两种记忆类别。明智地选择相关的记忆分类和检索机制，可以增强基于LLM的智能体在存储、管理和快速提取数据方面的能力，从而在应对挑战和完成任务时提升其效率和适应性。3.1.3 反思基于LLM的智能体的反思能力是指其对先前决策及其后续环境反馈进行评估的能力。这一能力使智能体能够深入审视其行为、决策过程和学习过程，从而增强其智能性和适应性。 当前关于基于LLM的智能体反思能力的研究可以根据学习方法大致分类，包括上下文学习（In-Context Learning）、监督学习（Supervised Learning）、强化学习（Reinforcement Learning）和模块化协调（Modular Coordination）方法。 
 图6：反思能力的类型上下文学习方法（In-Context Learning Methods） 如第3.1.1节所述，上下文学习（ICL）利用特定于任务的语言提示和实例进行强化。ReAct[125]实现了一种交互范式，在生成与任务相关的语言推理和行动之间交替进行，从而协同提升语言模型的推理和行动能力。这种方法在处理需要多样行动空间和推理的任务时表现出通用性和适应性。Reflexion[118]在每次行动后计算启发式指标，并根据自我反思决定是否重置环境，从而增强智能体的推理能力。 监督学习方法（Supervised Learning Methods） 监督学习通常依赖多种来源，包括大型语言模型、人类专业知识、代码编译器和外部知识。CoH[126]利用一系列带有反馈注释的先前输出，促进模型自我改进。这种技术采用监督微调、正负评分和经验回放来提升性能。Lightman等人[127]通过实验证实，在数学推理任务中，过程监督优于结果监督，且主动学习显著提升了过程监督的有效性。Introspective Tips[128]引入了一种基于过去轨迹或专家演示的自我检查框架，生成简洁但有价值的见解以优化策略。Zhou等人[129]提出了一种基于显式代码自我验证的提示方法，以优化GPT-4代码解释器的数学推理能力。此外，它还在推理步骤中加入了多样性验证器（Diversity Verifier），进一步增强智能体的推理能力。 强化学习方法（Reinforcement Learning Methods） 强化学习注重通过从历史经验中学习来优化参数。Retroformer[130]通过从回顾模型中学习并使用策略梯度自动调整基于LLM的智能体的提示来改进智能体。REMEMBER[54]引入了一种新颖的半参数强化学习方法，结合强化学习和经验记忆来更新记忆，并通过经验类比增强能力。Zhou等人[47]提供了一个对话塑造框架，通过从非玩家角色（NPCs）中提取相关信息并将其转化为知识图，加速智能体收敛到最优策略。REX[131]加入了一个辅助奖励层，并融合了类似上界置信度分数（Upper Confidence Bound scores）的概念，从而实现更稳健和高效的AI智能体性能。ICPI[132]展示了在无需专家演示或梯度的情况下执行强化学习任务的能力，通过在强化学习环境中通过试错交互迭代更新提示内容。Liu等人[135]通过在贝叶斯自适应马尔可夫决策过程（MDP）中整合智能体规划和行动，利用记忆缓冲区构建未知环境的更新后验以进行学习，同时生成多步未来的最优轨迹以最大化价值函数用于规划。Wang等人[136]提出了一种技术，使基于LLM的智能体通过与环境和其他智能体的迭代探索及近端策略优化（PPO）[137]训练实现持续改进。此外，该方法还便于将短期经验整合到长期记忆中。 模块化协调方法（Modular Coordination Methods） 模块化协调方法通常包括多个协同工作的模块，以促进基于LLM的智能体的规划和反思。DIVERSITY[133]探索多种提示以增强推理路径的多样性，通过加入一个验证器区分有利和不利的响应，实现了增强的加权投票，并使用多样性验证来确定每一步的正确性。DEPS[134]框架通过描述符、解释器和目标选择器与LLM规划器交互，提高整体成功率。PET[53]利用LLM知识简化具身智能体的控制问题，该框架包括规划、消除和跟踪模块，以完成更高级别的子任务。Dasgupta等人[70]研究了将规划者、行动者和报告者整合为一个三方系统。该系统在分布式学习中展示了泛化能力，探讨了失败场景，并描述了强化学习如何训练各个组件以提升性能。 这些方法和框架通过环境反馈、自我学习和反思优化了基于LLM的智能体的性能。它们在增强基于LLM的智能体的反思和重新规划能力方面取得了显著进展。3.1.4 环境基于LLM的智能体可以通过环境反馈与各种环境交互并从中学习。这些环境大致可以分为计算机环境、游戏环境、编码环境、现实世界环境和仿真环境。 
 图7：环境的类型计算机环境（Computer Environment） 在计算机环境中，基于LLM的智能体与网站、API、数据库和应用程序交互，覆盖计算机、网络和移动场景。交互方式包括： - 网页抓取（Web Scraping）：从网站收集信息以获取必要的数据和知识。  - API调用（API Calls）：使用Web API访问或传输数据，促进与在线服务的交互。  - 网络搜索（Web Searching）：利用搜索引擎发现相关信息和资源，用于解决问题或完成任务。  - 软件交互（Software Interaction）：操作并与软件应用程序交互，从文字处理器到图形设计工具，以高效执行任务。  - 数据库查询（Database Queries）：直接访问和更新数据库，实现实时数据处理和管理。  当代研究引入了一些方法，例如RCI[138]，它指导语言模型通过自然语言命令执行计算任务。WebArena[139]提供了一个独立的、自托管的网络环境，用于构建自主智能体。WebGPT[140]利用搜索引擎进行文档检索，支持端到端的模仿和强化学习，以优化检索和聚合，同时生成引用网络检索信息的响应。Mobile-Env[141]允许智能体观察Android操作系统的屏幕截图和视图框架，支持诸如点击屏幕或输入命令等操作，以与Android应用程序交互。SheetCopilot[142]通过自然语言促进与电子表格的交互。 游戏环境（Gaming Environment） 在游戏环境中，基于LLM的智能体与虚拟角色、物体和场景交互。游戏环境中的交互方法包括： - 角色控制（Character Control）：通过发出命令（如移动、跳跃、攻击）直接控制游戏中的角色。  - 环境交互（Environmental Interactions）：与游戏环境中的物体交互（如拾取、使用、放置）以完成任务。  - 状态感知（State Perception）：从游戏环境中收集状态信息（如角色位置、物品数量）以进行决策和规划。  典型应用包括DECKARD[48]，它在Minecraft游戏中部署LLM引导的探索来设计任务。VOYAGER[50]是一个基于Minecraft的LLM驱动的终身学习智能体，持续探索世界，获取各种技能并发现新事物。GITM[51]采用“间接映射”方法，将长期且复杂的目标转化为一系列低级的键盘和鼠标操作，促进在Minecraft游戏中的高效和灵活操作。AgentSims[143]生成一个虚拟小镇，包含多样化的建筑和居民，简化任务设计并解决研究人员因背景和编程专长差异可能遇到的挑战。LLM-Deliberation[144]建立了一个灵活的测试平台，用于文本形式的、多智能体、多议题且语义丰富的谈判游戏。此外，该平台支持轻松调整难度级别。 编码环境（Coding Environment） 编码环境使基于LLM的智能体能够编写、修改和执行代码，以完成各种任务，从编码到通过代码验证推理。编码环境中的交互方法包括代码生成、代码调试和代码评估。代码生成根据任务需求生成代码片段或完整程序。代码调试识别并修正代码中的错误或问题。代码评估执行代码并评估其性能，根据运行时错误消息或输出对其进行优化和改进。 LLift [145] 构成一个完全自动化的智能体，它与静态分析工具和大型语言模型（LLM）接口，以解决诸如特定错误建模、广泛的问题范围和LLM的非确定性等挑战。MetaGPT [67] 将人类工作流程融入LLM驱动的协作中，采用标准操作程序（SOPs）作为提示，以促进结构化的协调。类似地，Dong等人 [68] 引入了一个涉及多个LLM角色的自我协作框架，用于自动生成代码。在此框架中，不同角色分别承担分析师、程序员、测试员等职责，形成一个协作团队以完成代码生成任务。ChatDev [66] 代表一个虚拟的聊天驱动软件开发公司，基于瀑布模型将开发过程分为四个离散的顺序阶段：设计、编码、测试和文档。CSV [129] 通过提示解释器利用代码进行自我验证来增强数学推理能力，通过指示已验证状态提升解决方案的置信度。现实世界环境（Real-World Environment） 基于LLM的智能体可以与现实世界的设备、传感器和执行器交互，促进其在现实场景中的操作。这些情况下的交互方法包括： • 数据收集：基于LLM的智能体可以从摄像头和麦克风等传感器中积累实时数据，这些数据随后被用于分析和决策。  • 设备控制：在设备控制方面，基于LLM的智能体可以通过传输控制信号操作机器人手臂和无人机等执行器，从而完成特定任务。 • 人机交互：在人机交互方面，基于LLM的智能体擅长与人类用户进行自然语言沟通，能够接收指令、提供反馈并回应查询。  Di Palo 等人 [55] 引入了一个以语言为中心的推理工具包框架，在稀疏奖励的机器人操作环境中进行了测试，其中机器人执行诸如堆叠物体之类的任务。TaPA [146] 提出了一个嵌入式任务规划智能体，用于在物理场景约束下的现实世界规划。Alexa Prize 项目中的 SimBot 挑战 [147] 旨在构建能够在模拟物理环境中完成任务的机器人助手。Zheng 等人 [148] 提出了23种启发式方法，用于指导基于LLM的智能体与人类协作并共同创建服务。 仿真环境（Simulation Environment） 基于LLM的智能体在模拟环境中使用代表现实世界系统或过程的虚拟模型，例如经济市场、物理环境和交通系统。模拟环境中的交互方法包括： • 模型操作：调整模拟模型中的参数或变量以探索各种场景并分析其结果。  • 数据分析：收集并分析模拟生成的数据，以识别模式、趋势和洞见，从而为决策提供信息。  • 优化：应用优化算法在模拟环境中确定最佳行动方案，同时考虑约束条件和目标。  在近期研究中，TrafficGPT [149] 展示了在交通模拟环境 SUMO [150] 中执行交通流量分析和回答问题的能力。Li 等人 [34] 研究了模拟社交平台中社交智能体的行为特征。Horton [30] 探索了基于LLM的智能体在经济模拟场景中的行为，并比较了智能体与实际人类行为之间的差异。AucArena [151] 是一个拍卖模拟环境，其中智能体必须考虑资源和风险管理因素。这些模拟环境为基于LLM的智能体提供了一个受控但逼真的背景，使其能够学习、实验并开发适用于现实场景的解决方案，促进从虚拟领域到现实应用的知识和技能转移。 总之，基于LLM的智能体通过自然语言交互和环境反馈在各种环境中学习和应用知识，为不同任务提供稳健的解决方案。3.1.5 行动基于LLM的智能体的行动能力涉及执行行动或使用工具。此类智能体的主要交互方式通常是通过文本生成，与外部环境进行通信，这一特征类似于Generative Agents[63]。另一种方法是将大型语言模型或智能体与工具结合使用，包括API、计算器、代码解释器，或通过文本指令在物理环境中执行行动。这进一步延伸到工具的战略规划和部署，可能需要开发新工具来实现其实施。 
 图8：行动的类型工具使用（Tool Employment） MRKL[152]整合了大型语言模型和外部工具来解决复杂问题。这包括构建模块和路由器，并对自然语言查询进行路由。TALM[153]将语言模型与工具连接起来，支持文本到文本的API连接。ToolFormer[154]展示了大型语言模型利用外部工具的能力，提升了在各种任务中的性能。HuggingGPT[155]结合多个AI模型和工具进行任务规划和执行，包括文本分类和对象检测。《基于基础模型的工具学习》探讨了工具学习，提出了一个通用框架，将基础模型与工具集融合以实现高效的任务执行。Gorilla[157]深入研究了大型语言模型在API调用、程序合成、上下文学习和任务分解中的应用，以提升性能。RestGPT[158]是一种将大型语言模型与RESTful API连接的方法，以响应用户请求，包括在线规划和API执行。TaskMatrix.AI[166]能够理解文本、图像、视频、音频和代码等多种输入，随后生成调用API的代码以完成任务。D-Bot[159]提供数据库维护建议，涵盖知识检测、根本原因分析和多LLM协作。 Chameleon[156]使用各种工具应对挑战，并利用自然语言规划器选择并组合存储在库存中的模块，从而构建解决方案。AVIS[160]是一个自主视觉信息搜索系统，利用大型语言模型动态制定策略，使用外部工具并检查其输出结果，以获取回答提问所需的关键知识。 工具规划（Tool Planning） ChatCoT[161]将链式思维建模为多轮对话，通过工具辅助推理改进复杂任务处理。TPTU[162]引入了一个任务执行框架，包括任务指令、设计提示、工具包、大型语言模型、结果以及任务规划和工具使用能力。ToolLLM[74]基于深度优先搜索开发了一个决策树，使大型语言模型能够评估多个基于API的推理路径并扩展搜索空间。Gentopia[163]是一个框架，允许通过简单配置灵活定制智能体，将各种语言模型、任务格式、提示模块和插件无缝整合到一个统一范式中。 工具创建（Tool Creation） Cai等人[164]提出了一个工具创建和使用框架，生成适用于多样化任务的工具，涵盖分阶段工具生成和任务执行。CRAFT[165]是一个专为开发和检索通用工具设计的框架，能够生成针对特定任务的专用工具包。大型语言模型可以从这些工具包中提取工具以应对复杂任务。 3.2 基于LLM的多智能体系统3.2.1 多智能体系统的关系在基于LLM的多智能体系统（MAS）中，许多智能体通过协作、竞争或层次组织来执行复杂任务。这些任务可能包括搜索和优化、决策支持、资源分配、协作生成或控制。在这些系统中，智能体之间的相互关系至关重要，因为它们决定了智能体之间的交互和协作机制。同样，这些智能体间的关系可以推广到基于LLM的多智能体系统中。目前，基于LLM的多智能体系统的大多数研究主要聚焦于智能体之间的合作和竞争动态。 
 图9：多智能体系统的关系合作关系（Cooperative Relationship） 在合作关系中，学术关注主要集中在角色和任务分配策略以及协作决策算法上。这些方法可以提高智能体协作的效率，从而改善整体系统性能。SPP[172]通过多角色自我合作实现多轮对话，将单一大型语言模型转变为认知协同者。Generative Agents[63]利用基于LLM的智能体模拟可信的人类行为，从而促进智能体之间的合作。CAMEL[173]通过面向任务的角色扮演实现AI助手与AI用户之间的多轮对话合作。MetaGPT[67]将有效的工作流程整合到LLM驱动的多智能体协作编程方法中，支持不同角色之间的协作。ChatDev[66]利用多个基于LLM的智能体进行对话任务解决，加速LLM应用开发。 受明斯基的“心智社会”[23]启发，NLSOM[24]提出了基于自然语言的心智社会（NLSOMs）的概念，包括多个大型语言模型和其他基于神经网络的专家，通过自然语言接口进行通信。这一方法应用于处理各种场景中的复杂任务。Zou等人[174]实现了设备端大型语言模型之间的协作。在具身多智能体系统中，RoCo[175]使用大型语言模型进行高级通信和低级路径规划，促进多机器人协作。InterAct[176]分配了诸如检查者和分类者等角色，在AlfWorld[177]中取得了显著的成功率。AutoAgents[85]可以自适应生成并协调多个专业智能体，根据各种任务组成AI团队以实现目标。 在基于LLM的多智能体系统框架研究中，BOLAA[167]设计了一个架构，用于协调多智能体策略，增强单个智能体的行动交互能力。AgentVerse[84]提供了一个多功能框架，简化了为大型语言模型创建定制多智能体环境的过程。Zhang等人[73]提出了一个新颖的框架，使具身智能体能够规划、通信并协作，与其他具身智能体或人类高效完成长期任务。CGMI[168]是一个可配置的通用多智能体交互框架，利用大型语言模型的能力解决特定任务中智能体的性能挑战并模拟人类行为。Gentopia[163]是一个通过简单配置允许灵活定制智能体的框架，将各种语言模型、任务格式、提示模块和插件无缝整合到一个统一范式中。DyLAN[178]引入了一个基于任务的动态框架，使多个智能体能够交互，并提出了一个基于无监督指标的自动智能体团队优化算法，根据每个智能体的贡献选择最有效的智能体。 竞争关系（Competitive Relationship） 在竞争关系中，考虑因素包括设计有效的竞争策略、信息隐藏技术和对抗行为。这些技术可以帮助智能体在竞争中获得优势，从而实现其目标。Liang等人[169]通过多智能体辩论框架增强了任务解决能力。ChatEval[16]采用多智能体方法，使一组大型语言模型与各种智能对手协作，利用各自的能力和专长提高处理复杂任务的效率和效果。 混合关系（Mixed Relationship） 在混合关系中，智能体必须平衡合作与竞争以实现其目标。目前，基于LLM的多智能体系统中关于混合关系的研究集中在协作竞争算法的设计上，这是一个关键课题。这些技术可以帮助智能体在复杂环境中做出有效决策。Xu等人[170]使多个基于LLM的智能体参与狼人游戏，每个智能体在不对称信息条件下合作或背叛其他智能体，以实现其角色的目标。类似地，Light等人[171]使基于LLM的智能体参与Avalon游戏，每个智能体在动态发展的游戏阶段中必须做出决策，并与其他智能体进行涉及合作或欺骗的谈判，以完成其指定角色的目标。受人类行为启发，Corex[179]融入了多种协作范式，如辩论、审查和检索模式。这些模式共同努力提升推理过程的真实性、忠实度和可靠性。 层次关系（Hierarchical Relationship） 在层次关系中，研究人员关注开发高效的层次控制结构、信息传输机制和任务分解方法。这些技术使智能体能够在不同层级间有效协作，从而增强系统的整体性能。层次关系通常表现为树形结构，其中父节点智能体负责任务分解并将任务分配给子节点智能体。子节点智能体遵循相应父节点的安排并返回汇总信息。AutoGen[83]利用不同智能体处理任务，如代码生成和文本编写，通过对话进行任务分解。目前，基于LLM的多智能体系统中对层次关系的研究仍在发展中，仅探索了有限的层级。 在未来的研究中，利用博弈论、拍卖机制和谈判技术有望解决合作智能体之间任务分配的问题。此外，分布式约束优化问题（DCOP）为研究合作智能体内的协作决策提供了重要框架。在其他关系类型中，合作博弈和多目标强化学习（MORL）成为探索合作与竞争之间微妙平衡的关键框架。这些已建立的研究框架也可以在基于LLM的多智能体系统中进行调整和优化。3.2.2 规划类型在多智能体系统（MAS）领域，规划是一个关键组成部分，因为它使多个智能体能够协调一致以追求共同目标。研究人员提出了多种规划方法，每种方法都有其独特的优点和局限性。类似于多智能体强化学习中的集中式训练分散式执行（CTDE）[180]概念，本研究探讨了两种主要的规划范式：集中式规划分散式执行（CPDE）和分散式规划分散式执行（DPDE）。  
 图10：多智能体系统规划类型的分类集中式规划分散式执行（Centralized Planning Decentralized Execution, CPDE） 在CPDE范式中，一个集中式的大型语言模型负责为系统中所有智能体进行规划。这要求该模型考虑所有智能体的目标、能力和约束，为它们制定适当的行动计划。如Gong等人[181]所述，规划者必须同时管理多个智能体，避免潜在冲突，并协调它们以实现需要复杂协作的共同目标。规划完成后，每个智能体独立执行其指定任务，不再与集中式大型语言模型进一步交互。这种方法的优点在于能够从全局角度优化整体性能，因为集中式模型可以综合考虑所有智能体的需求和资源。Li等人[72]在Overcooked[182]和MiniRTS[183]多智能体环境中开发了SAMA，通过使用集中式大型语言模型实现目标生成、目标分解、目标分配和自我反思的重新规划。 然而，CPDE也存在一些局限性。首先，集中式规划过程可能导致计算复杂度的增加，特别是在管理大量智能体和复杂任务时。其次，由于所有智能体依赖单一的大型语言模型进行规划，系统可能容易出现单点故障和通信延迟。最后，CPDE可能不适合需要实时响应和高适应性的场景，因为集中式模型可能无法快速应对环境变化。 分散式规划分散式执行（Decentralized Planning Decentralized Execution, DPDE） 与CPDE相反，DPDE系统中每个智能体配备独立的LLM负责行动规划。因此，每个智能体可以根据其目标、能力和本地信息独立制定计划。在执行阶段，智能体可以通过本地通信和协商增强协作。 DPDE的优点包括更高的鲁棒性和可扩展性，因为每个智能体独立规划和执行，从而减轻了集中式模型的计算负担。此外，DPDE系统通常表现出更强的适应性，因为每个智能体可以根据本地信息迅速调整其行为。这一特性使DPDE系统更适合动态和不确定的环境。 然而，DPDE的局限性包括难以实现全局最优，因为每个智能体的规划依赖于本地信息。此外，在大规模系统中，协调和通信开销可能变得显著，可能会影响整体性能。 在DPDE系统中，智能体之间的信息交换对于促进合作和协作至关重要。以下讨论将DPDE系统中智能体之间的信息交换分为三类： 无通信的信息交换（Information Exchange Without Communication） 在这种模式下，智能体不进行直接通信。每个智能体独立规划和执行，仅依赖本地信息和观察来完成任务。这种方法的优点在于通信开销极小，因为智能体无需交换信息。此外，在通信受限或不可靠的环境中，这种方法可能是唯一可行的选择。 然而，缺乏通信可能导致智能体之间的协作次优，因为它们无法共享信息、协调行动或解决冲突。在某些情况下，这可能导致低效行为和整体性能下降。 有通信的信息交换（Information Exchange With Communication） 在这种模式下，智能体通过显式通信进行信息交换和行动协调。通信可以采取多种形式，包括消息传递、广播或点对点通信。通过通信，智能体可以分享观察、目标、计划和其他相关信息，从而增强协作和整体性能。 然而，通信可能会带来额外的开销，包括通信延迟、带宽使用和处理接收信息的成本。此外，在通信不可靠或受限的环境中，这种方法可能面临诸如消息丢失或更新延迟等挑战。 共享记忆的信息交换（Information Exchange With Shared Memory） 在这种模式下，智能体通过共享记忆交换信息，共享记忆是一个所有智能体都可以访问和修改的集中式数据结构。智能体通过在共享记忆中存储和检索信息来实现信息共享和协作。 共享记忆具有多项优点，例如简化通信，因为智能体无需直接发送和接收消息。此外，它提供了统一的信息表示和访问机制，简化了系统的设计和实现。 然而，共享记忆也存在一些局限性。首先，当所有智能体需要访问和修改共享记忆时，可能会出现争用和同步问题。其次，共享记忆可能限制系统的可扩展性，因为需要保持所有智能体之间的一致性。最后，在分布式和移动智能体环境中实现共享记忆可能面临技术挑战，例如确保数据一致性和管理并发控制。 在当代研究中，可以识别出两种形式的共享记忆： - 中央知识库（Central Knowledge Base）：可以建立一个中央知识库来存储和管理每个智能体的共享知识。该知识库可以是数据库、知识图或其他存储结构。智能体通过查询和更新此知识库实现记忆共享。MetaGPT[67]提供了一个全局记忆池来存储所有协作记录，使每个智能体能够订阅或搜索所需信息。这种设计允许智能体主动观察和提取相关信息。  - 共享参数（Shared Parameters）：在某些情况下，可以考虑在基于LLM的多智能体系统中允许部分或全部模型参数在智能体之间共享。通过这种方式，当一个智能体获得新知识或技能时，其他智能体也可以立即获取这些信息。然而，这种方法可能引发过拟合或过度专业化问题。为解决这一问题，可以动态调整共享参数的权重，以平衡每个智能体的专业化和泛化能力。  3.2.3 提升通信效率的方法在基于LLM的多智能体系统中，通信效率低下和大型语言模型的幻觉问题确实可能发生。为了缓解这些问题，可以采用以下策略： 
 图11：提升通信效率方法的分类设计有效的通信协议（Design Effective Communication Protocols） 在多智能体系统领域，有必要从“何时（when）”、“何事（what）”和“如何（how）”三个维度审视通信的讨论。这些维度共同决定了智能体之间交互的时机、内容和方式，是系统在复杂问题解决和协调任务中有效性的关键因素。 可以识别出智能体通信的四个层次： - 消息语义（Message Semantics）：每条消息的含义。 - 消息语法（Message Syntax）：每条消息的表达方式。 - 智能体通信/交互协议（Agent Communication/Interaction Protocol）：对话/会话的结构。 - 传输协议（Transport Protocol）：智能体发送和接收消息的方法。 历史上，基于强化学习的智能体主要通过学习进行隐式通信。相比之下，基于LLM的智能体可以通过自然语言处理（NLP）进行通信，为人类提供更透明和显式的交互方式。因此，在基于LLM的多智能体系统中，关于消息语义和传输协议的担忧得以消除。 消息语法的问题指向了智能体通信语言（Agent Communication Language, ACL），它基于Searle提出的言语行为理论（Speech Acts Theory）[184]。出现了两个突出的标准：知识查询与操作语言（KQML）[185]和智能物理代理基金会（FIPA）提出的ACL³。³ http://www.fipa.org/1996年，FIPA为异构和交互智能体及基于智能体的系统开发了标准。FIPA的ACL包括22种行为（performatives）或通信行为，例如“通知（Inform）”和“请求（Request）”。这些行为不是孤立的实体，而是作为智能体之间结构化对话协议的组成部分发挥作用。此类协议由预定义规则管理，这些规则概述了行为使用的顺序和时机，以实现特定的集体目标。例如，FIPA-ACL可以构建FIPA拍卖-英国协议（FIPA-Auction-English Protocol）和FIPA拍卖-荷兰协议（FIPA-Auction-Dutch Protocol）。 实施定义明确的通信协议可以确保智能体交互遵循一致的结构和语义，减少歧义和误解，从而提升通信效率。采用嵌入（embeddings）[186]或结构化输出格式（如JSON）可以进一步增强这些优势。 使用中介模型（Employing Mediator Models） 在基于LLM的多智能体系统中，大型语言模型之间的大量交互可能导致成本增加和参与时间延长。中介模型作为一个判断机制，帮助确定大型语言模型之间交互的必要性，从而减少冗余通信开销并提升系统的整体效率。中介模型决定是否进行交互的依据包括任务复杂性、智能体间关联程度和通信成本。现有的研究已见证中介模型的实施，例如Hu等人[52]和Karimpanal等人[121]的研究，深入探讨了优化智能体与大型语言模型之间成本效益高的智能交互。 缓解大型语言模型的错误输出（Mitigating Inaccurate Outputs in LLMs） 大型语言模型经常倾向于生成过度赞美或无根据的信息。Wei等人[187]的研究引入了一种简单方法，通过在辅助微调阶段使用合成数据来减少奉承输出的发生。Rawte等人[188]提供了对大型语言模型幻觉问题的全面分析以及对抗这些问题的技术。验证链（Chain of Verification, CoVe）[189]旨在通过以下步骤减少幻觉：提示模型首先生成初步响应，随后为事实核查该草稿制定验证问题，独立回答这些问题，最后生成经过验证和优化的最终响应。 通过实施这些策略，可以有效解决基于LLM的多智能体系统中通信效率低下和大型语言模型幻觉的问题，从而最终提升系统的性能和稳定性。 4 性能评估4.1 数据集大多数基于LLM的智能体无需进一步训练大型语言模型，且某些特定任务的数据集并未公开。因此，我们仅列举了公开可用且被广泛使用的数据集。 表3：研究中使用的数据集
 4.2 基准目前，尚无广泛使用的基于LLM的智能体基准，尽管一些研究对它们的基于LLM的智能体与其他智能体进行了比较分析。此外，研究人员正在努力提出可能作为未来评估标准的基准。 ToolBench[74] 是一个用于工具使用的指令调整数据集，涵盖单工具和多工具场景。TE[199] 评估语言模型模拟人类行为各个方面的能力。Akata等人[200] 旨在理解大型语言模型的社会行为，为机器行为博弈论奠定了基础，强调了理解大型语言模型在交互社交环境中的运作对社会的重大价值。Ziems等人[201] 提供了一套提示最佳实践的汇编和一个全面的评估流程，以评估13种语言模型在24个代表性CSS（计算社会科学）基准上的零样本性能。 AgentSims[143] 提供了一个用于LLM评估的开源平台。Drori等人[41] 收集了麻省理工学院（MIT）和哥伦比亚大学计算线性代数课程中最大规模数学课程的问题数据集，以评估数学推理能力。BMTools[196] 建立了工具使用的框架和评估标准。SmartPlay[202] 提出了一个具有挑战性的基于LLM的智能体基准，包括六种独特的游戏，每种游戏具有独特的设置，提供多达20种评估配置和无限的环境变化。MLAgentBench[203] 是一套用于AI研究智能体基准测试的机器学习任务集合，支持诸如读写文件、执行代码和检查输出等操作。MetaTool[204] 用于评估大型语言模型是否有意识地使用工具并选择合适的工具。LLM-Co[205] 评估智能体在游戏环境中推断合作者意图、进行推理行动和参与长期协作的能力。 5 前景应用
 图12：基于LLM的智能体的前景5.1 自然科学5.1.1 数学近年来，许多研究集中于数学领域的智能体和多智能体系统。例如，Kennedy和Eberhart[206]提出了粒子群优化算法，这是一种基于多智能体框架的全局优化技术，广泛用于解决数学、工程和计算中的优化挑战。Macal和North[207]讨论了基于智能体的建模和仿真方法及其在复杂数学模型中的实现。Crainic和Rousseau[208]探索了基于智能体的方法在组合优化问题中的应用，特别是在设计多商品、多模式运输网络方面。 当前，基于LLM的智能体在数学领域的研究主要侧重于增强推理能力和支持理论推导。例如，Math Agents[40]利用大型语言模型探索、发现、解决和演示数学问题。Zhou等人[129]引入了一种创新且高效的提示技术，称为基于代码的自我验证，以进一步提升GPT-4代码解释器的数学推理潜力。LeanDojo[209]是一个工具，能够持续与Lean交互，纠正现有定理证明工具中的证明检查错误。Dong等人[210]通过与GPT-4进行97次严格的“苏格拉底式”推理，最终确定“P ≠ NP”。Yang等人[211]设计了一个系统，仅使用原始网络文本集合就能自主生成有效、原创且有价值的假设。ToRA[212]提出了一系列工具集成推理智能体，利用自然语言推理并调用外部工具解决复杂的数学问题。COPRA[213]用于形式定理证明，将GPT-4作为其状态回溯搜索策略的关键组成部分，能够在搜索过程中选择证明策略并从外部数据库检索公理和定义。 基于LLM的智能体在未来数学研究中展现出巨大潜力，包括以下方面： - 辅助理论推导（Aiding in Theoretical Derivation）：基于LLM的智能体能够理解数学和物理等领域的基础理论，并协助人类进一步推导和验证，促进科学探究的进展。 - 符号与数值计算（Symbolic and Numerical Computation）：基于LLM的智能体可用于符号和数值计算，支持研究人员解决各种数学难题。智能体可以执行多种数学操作，包括解方程、积分、求导等。多智能体系统通过协作将复杂的数学问题分解为多个子问题，从而提升计算速度和精度。 尽管基于LLM的智能体在数学理论推导和计算方面取得了一些成就，但仍需持续改进大型语言模型及其智能体的数学推理能力，并设计更有效的数学知识表示方法，以提高它们在处理复杂数学问题时的准确性和效率。此外，基于LLM的智能体在解决数学问题时的可解释性和可靠性至关重要。探索额外方法以增强智能体的可解释性，使其能够为用户提供更清晰可靠的解决方案，是非常重要的。同时，对智能体推理结果的监督和验证可以确保其在实际应用中的可靠性。5.1.2 化学与材料在先前研究中，Gómez-Bombarelli等人[214]提出了160万个有机发光二极管材料候选物，通过高保真仿真从庞大的分子库中有效筛选出来。MolDQN框架[215]结合化学领域知识与强化学习方法，明确描述分子修改，确保100%的化学有效性。You等人[216]提出了图卷积策略网络（GCPN），这是一个基于通用图卷积网络的模型，通过强化学习生成目标导向的图，旨在发现具有期望属性（如药物相似性和合成可行性）的新分子。Beaini等人[217]引入了Graphium图机器学习库，简化了在多任务和多层次分子数据集上构建和训练分子机器学习模型的过程。 在基于LLM的智能体在化学和材料科学领域的当前研究中，Coscientist[218]利用大型语言模型的功能，结合互联网和文献搜索、代码执行和实验自动化等工具，能够自主设计、规划和执行现实世界的化学实验。ChatMOF[39]致力于预测和生成金属-有机框架（MOFs），包括三个核心组件：智能体、工具包和评估器。这些组件能够处理数据检索、属性预测和结构生成。ChemCrow[38]通过访问与化学相关的数据库，执行生物合成、药物发现和材料设计等领域的各种化学任务，从而加速更高效的研究。基于LLM的智能体还在以下方面展现出巨大潜力： - 分子仿真与化学反应优化（Molecular Simulation and Chemical Reaction Optimization）：基于LLM的智能体可以通过模拟分子结构和化学反应，推动化学和材料科学研究。通过检查不同的反应路径和条件，这些智能体可以识别合成新材料或优化现有材料属性的有效策略。 - 化学实验自动化与智能化（Chemical Experiment Automation and Intelligence）：基于LLM的智能体可以通过检索信息、查询专用数据库以及设计和实施针对特定需求的实验计划，促进化学实验的自动化。这有助于获取化学反应和材料属性的数据。此外，多智能体系统可以通过协作合作和共享实验数据及经验，提高实验的效率和精度。 - 材料设计与优化（Material Design and Optimization）：在材料科学研究中，基于LLM的智能体可以协助模拟和优化材料属性。通过自主探索各种材料组合和结构，并利用强大的泛化信息，智能体可以预测材料属性，加速材料设计过程并提升整体效率。 尽管现有的基于LLM的智能体在化学和材料科学研究中取得了一些成功，但进一步提高模型的准确性和可靠性仍是一个重大挑战。未来研究应专注于增强大型语言模型处理复杂化学和材料问题的能力，以提高预测和生成化学反应、材料属性等方面的准确性。5.1.3 生物学近年来，生物学领域涌现出许多关于智能体和多智能体系统的成熟研究。例如，Bonabeau等人[219]探讨了群体智能的理论与应用，包括基于多智能体模型的遗传算法、蚁群算法和粒子群算法。DeAngelis和Mooij[220]提供了生态研究中个体建模方法的全面概述，模拟生态系统内的物种交互和环境影响。Wilensky和Rand[221]介绍了基于智能体的建模方法及其在自然、社会和工程复杂系统中的应用，包括使用智能体系统模拟海洋生态系统和大气循环等地理科学问题。Jain等人[222]提出了一种主动学习算法，利用GFlowNets作为生成器，生成多样化的候选解决方案，旨在产生具有最优特性的生物序列，如蛋白质和DNA序列。 目前，基于LLM的智能体在生物学领域的研究较为有限。Bioplanner[223]是一种自动化评估方法，用于评估大型语言模型在生物学领域协议生成和规划任务中的性能。OceanGPT[224]采用多智能体协作，自动生成海洋科学各个子领域的数据。尽管如此，未来的研究在以下领域具有巨大潜力： - 生态系统建模（Ecosystem Modeling）：基于LLM的智能体可以模拟生态系统中物种交互和环境影响，帮助研究人员理解生态系统的结构和功能。例如，通过模拟生物个体、种群和环境的行为和交互，可以分析生态系统的稳定性、多样性和演化过程。 - 群体行为与集体智能（Group Behavior and Collective Intelligence）：通过模拟群体内的行为和交互，可以阐明群体行为、集体智能、种群遗传学和演化的基本概念。特别是通过模拟多个智能体（如分子或生物群体）的行为和交互，可以研究群体行为的形成、协调、适应和演化，从而更好地理解整个系统功能的机制。 - 细胞生物学与分子生物学（Cell Biology and Molecular Biology）：基于LLM的智能体可以模拟细胞内的分子机制和信号通路，进而研究生物分子之间的交互和调控。例如，通过模拟多个智能体（如蛋白质、核酸和代谢物）的行为和交互，可以分析细胞内信号传导、基因表达调控和代谢途径等生物过程。 生物系统以其固有的复杂性而著称，这种复杂性体现在多个层次、时空尺度和时间跨度上。因此，使用LLM的智能体必须展示处理这种复杂性的能力。这包括考虑生物实体的动态行为和交互，例如个体生物、种群及其生态背景。此外，生物学领域的数据通常具有体量大、多样性强、结构异构和固有噪声的特点，这在基因组、表型和环境信息等数据集中尤为明显。因此，基于LLM的智能体需要具备有效处理大量异构数据并从中提炼有价值见解和知识的能力。5.1.4 气候科学在大气研究中，智能体系统的应用主要涵盖气候行为阐释和气候能源经济学研究等领域。Jager[225]提出了一种新颖的基于智能体的建模方法，阐述了其在解析与气候相关的行为动态复杂性方面的效用。Castro等人[226]对以气候-能源政策为中心的研究进行了全面审查，强调通过实施基于智能体的建模方法来减少排放和节约能源。 在当前的研究格局中，Kraus等人[227]利用基于LLM的智能体从ClimateWatch⁴提取排放数据，从而提供更准确和可靠的数据，这些数据与气候变化的关键方面密切相关。基于LLM的智能体可以通过在不同地理位置部署传感器网络收集大气数据（如温度、气压、湿度、风速），并通过基于LLM的智能体对这些数据进行实时分析和处理，从而用于气候变化预测。这种方法还可以预测或发布大气现象和气候变化的警报。另一方面，在气候模型仿真与优化方面，基于LLM的智能体可以模拟各种大气过程和事件，如大气环流、气候系统和空气污染传播。通过不断优化和修改智能体之间的交互规则，模型可以调整以更准确地反映现实世界场景，最终为大气科学研究提供更精确的预测和解决方案。在气候模拟过程中，多智能体系统的日益复杂性对计算效率提出了重大挑战。提升基于LLM的智能体的规划和反思性能对于在有限计算资源下实现更精确的气候仿真和预测至关重要。此外，由于大部分大气数据是数值型的，增强大型语言模型对数值的理解和计算能力将显著影响系统性能。 5.2 通用自主智能体5.2.1 通用任务助手当前关于通用任务助手的研究主要集中在基于LLM的智能体系统或框架上。通用智能体（Generalist Agent）[18]是一个多模态、多任务和多实体的通用智能体，能够执行各种任务，例如玩Atari游戏、命名图像、聊天、用真实机器人手臂堆叠积木等。HuggingGPT[155]整合了机器学习社区中不同领域的各种模块和AI模型，以执行任务规划。ModelScope-Agent[228]是一个通用的、可定制的基于LLM的智能体框架，适用于实际应用，提供用户友好的系统库。LangChain[77]是一个开源框架，通过自然语言通信和协作支持高效的软件开发。XLang[76]提供了一套全面的工具和用户界面，支持基于LLM的智能体进行数据处理、插件使用和网络场景。BabyAGI[59]根据预定义目标创建任务，利用大型语言模型生成新任务，并存储和检索任务结果。AutoGPT[75]是一个能够分解目标并循环执行任务的自动化智能体。AgentVerse[84]似乎是一种新的仿真方法和系统应用。（注：原文此处表述不完整，可能是OCR错误或未展开，我根据上下文推测并翻译。） 在通用任务助手中，利用特定领域的工具（如代码和仿真器）进行验证实验对于提升任务完成度和准确性至关重要。基于LLM的智能体还应具备更全面的跨领域知识和技能，以适应多样化的工作和研究需求。最终，创新和原创性是一个重大挑战，有必要增强基于LLM的智能体在工作和研究协助中的创造力和原创性，同时避免生成重复或过于相似的内容。 未来在基于LLM的智能体的工作和研究协助方面的努力可能进一步深入探索音乐和电影生成等艺术创作领域，并结合人机协作，利用人类知识生成更具原创性的作品，从而为人类工作和创造力提供更大的便利。5.3 社会科学5.3.1 经济学与金融现有的智能体和多智能体系统已在经济和金融研究中得到应用。Arthur等人[236]利用多智能体模型构建了一个人工股票市场，探索资产定价、投资者行为和市场波动等金融市场问题。Tesfatsion和Judd[237]全面介绍了基于智能体的计算经济学方法及其在各个经济领域的应用。Johanson等人[238]展示了智能体利用多智能体强化学习（MARL）在空间中生成资源并以其偏好的价格进行交易的能力。AI Economist[239]提出了一个具有竞争压力和市场动态的经济仿真环境，通过展示基础税收系统在经济一致性下的运行（包括学习和专业智能体的行为和专门化）验证了仿真。《AI Economist：利用AI驱动的税收政策提升平等和生产率》提出了一种基于经济仿真的双层深度强化学习方法，用于学习动态税收政策，智能体和政府在此过程中学习和适应。Tilbury[240]回顾了经典基于智能体技术在经济建模中面临的历史障碍。 目前，许多研究聚焦于经济学和金融中的基于LLM的智能体。Horton[30]通过将大型语言模型置于不同的经济场景中并探索其行为，与实际人类行为进行比较。这使研究人员能够在诸如独裁者博弈和最低工资问题的仿真中研究经济行为，为经济学提供新的见解。Phelps和Ranson[241]研究了大型语言模型在委托-代理冲突中的反应，发现基于LLM的智能体在一个简单的在线购物任务中会覆盖其委托人的目标，提供了委托-代理冲突的明确证据，并强调将经济学原理纳入对齐过程的重要性。AucArena[151]展示了基于LLM的智能体在拍卖中的高效参与，能够有效管理预算、保持长期目标，并通过显式激励机制提高适应性。 在博弈论领域，Suspicion-Agent[242]在各种不完美信息卡牌游戏中表现出卓越的适应性，展示了强大的高阶心智理论（Theory of Mind）能力，表明它能够理解他人并有意影响他们的行为。 许多研究探索了基于LLM的智能体在金融交易场景中的应用。AlphaGPT[243]引入了一个用于Alpha挖掘的交互框架，采用启发式方法理解量化研究人员使用的概念，随后生成创新、富有洞察力和高效的Alpha。TradingGPT[244]提出了一个新颖的基于LLM的多智能体系统框架，带有层次记忆，模拟人类认知过程以增强金融交易决策。该方法使智能体能够优先处理关键任务，整合历史行动和市场洞察，并进行智能体间讨论，提高响应性和准确性。 鉴于基于LLM的智能体在文本理解和复杂决策能力方面的增强，它们在经济学和金融研究中具有显著潜力。相关探索可能包括以下领域： - 市场仿真与模拟（Market Simulation and Emulation）：建立基于LLM的智能体来模拟各种市场参与者的行为，如供需双方、竞争者和监管者，使研究人员能够预测和模拟产品价格、市场份额、市场结构和交易完成率等数据。行为可能包括购买、竞标、讨价还价和协作投标。 - 金融市场分析（Financial Market Analysis）：通过模拟金融市场参与者的行为，包括投资者、机构和监管者，基于LLM的智能体可以为市场波动和风险提供有价值的见解。例如，模拟投资者交易行为和市场信息传播过程可以预测股票价格、汇率和利率的波动。 - 宏观经济与政策仿真（Macroeconomic and Policy Simulation）：基于LLM的智能体可以模拟财政和货币政策的实施过程，涵盖政府、企业和个人等各种经济主体。这使智能体能够预测宏观经济指标的变化，包括国内生产总值（GDP）、通货膨胀率和失业率。 - 社会经济网络分析（Socio-economic Network Analysis）：通过建模社会经济网络中的信息传播、资源分配和信任建立等过程，基于LLM的智能体有助于更深入理解网络经济学的演变和影响。具体来说，模拟消费者、企业和政府等不同智能体的行为，可以提供关于网络效应、信息不对称和市场失灵的见解。 对于在经济学中通常模拟人类或经济主体决策的基于LLM的智能体，智能体交互的行动空间和智能体的状态在实验结果中起着至关重要的作用，直接影响结果。有效表示交互行动空间和智能体状态，以更准确地模拟经济主体的决策过程，是一个重大挑战。同时，大型语言模型拟人化的可信度也是一个主要挑战。如果进行大规模宏观经济分析，可能需要许多基于LLM的智能体，这对系统性能或令牌消耗提出了困难。一种方法是使用强化学习方法控制和减少与大型语言模型的交互次数。5.3.2 政治学在政治学领域先前的智能体研究中，Epstein和Axtell[245]利用多智能体系统构建了一个人工社会，研究政治沟通和社会运动等社会现象的形成和演变。Lustick和Miodownik[246]讨论了多智能体系统在比较政治科学研究中的应用，涵盖政治系统、政治决策和政治稳定性。Tsvetovat和Carley[247]介绍了多智能体模型在研究复杂社会技术系统中的应用，包括政治学中的政治沟通和政治决策。Trott等人[248]利用双层强化学习和数据驱动仿真，实现有效、灵活且可解释的政策设计。 在当前的基于LLM的智能体研究中，这些智能体被用于探索政治主体的潜在决策和沟通情境。Ziems等人[201]使用基于LLM的智能体帮助理解政治家演讲的内容和策略。Bail[249]展示了基于LLM的智能体能够检测意识形态、预测投票结果并识别模式。Mukobi等人[250]提出了一个零和棋盘游戏外交的广义和变体，在该变体中，智能体必须平衡军事征服和国内福利的投资。 基于LLM的智能体在政治学领域可以探索以下方面： - 政治仿真与预测（Political Simulation and Prediction）：通过模拟政治过程中各种参与者的行为和交互，例如政党竞争、选民行为和政策制定过程，基于LLM的智能体可以预测政治事件的发展趋势、选举结果和政策效应。 - 政治决策分析（Political Decision-making Analysis）：利用基于LLM的智能体模拟不同政治决策过程的行为和交互，可以评估各种政策选择的优缺点及其影响。这种方法允许研究人员模拟政府、政党和利益集团之间的交互，为政策制定者提供关于政策效应的宝贵信息。 - 国际关系研究（International Relations Research）：利用基于LLM的智能体建模国际政治中国家之间的交互和冲突，研究人员可以探索国际贸易、军事冲突和外交互动等多个方面。这种方法有助于理解国际政治的复杂性和潜在风险。 在政治研究中，基于LLM的智能体可能需要确保通信效率，同时避免过度礼貌和无效沟通，以增强其在政治科学研究中的实际应用价值。同时，准确建模政治环境的复杂性和不确定性，以提高基于LLM的智能体在政治领域研究的准确性和可靠性，是一个挑战。当然，还需要确保基于LLM的智能体行为符合伦理和道德要求，避免对社会产生负面影响。5.3.3 社会学在社会学领域先前的多智能体研究中，Epstein和Axtell[245]利用多智能体模型构建了一个人工社会，研究社会运动、文化演变和社会变革等社会现象的形成和演变。Macy和Willer[251]介绍了计算社会学和基于智能体的建模方法，涵盖社会学中的社会网络、社会规范和社会影响。Gilbert和Troitzsch[252]提出了利用仿真方法为社会科学家服务的理论和实践，包括多智能体模型在社会学研究中的应用。Hasan等人[253]讨论了可持续发展的支柱（如社会、环境和经济）。 目前，基于LLM的智能体主要专注于模拟人类行为和社会交互。Generative Agents[63]提出了一种多智能体交互模式，以实现可信的人类行为仿真。Gao等人[33]使用提示工程和调整技术，创建了一个基于LLM的多智能体系统，模拟现实世界的社交网络数据，包括情感、态度和交互行为。Li等人[34]研究了在类似Twitter的社交网络中，由LLM驱动的社交机器人的行为特征，结果表明这些机器人可以通过毒性行为伪装并影响在线社区。Liu等人[254]提出了一种新颖的学习范式，使语言模型能够从模拟的社会交互中学习。Feng等人[255]研究了基于LLM的智能体在精心设计的环境和协议中模拟可信人类行为的能力。Wei等人[256]评估了多方群聊对话模型的性能，探索了增强模型性能的方法，并解决了轮流发言和对话连贯性的挑战。 另一方面，Li等人[35]开发了一个观点网络动态模型，以编码LLM的观点、个体认知接受度和使用策略，模拟LLM在各种场景下对观点动态的影响。LLM-Mob[257]利用LLM的语言理解和推理能力，通过引入历史停留和上下文停留的概念分析人类迁移数据，捕捉人类移动的长期和短期依赖，并利用预测目标的时间信息进行时间感知预测。Egami等人[258]利用LLM输出进行社会科学中文档标签的下游统计分析，同时保持统计特性，如渐进无偏性和准确的不确定性量化。Ghaffarzadegan等人[259]探索了利用生成式人工智能构建具有复杂反馈的计算模型的新兴机会，这些模型可以描绘社会系统中个体的决策过程。Lyfe Agents[260]评估了智能体在各种多智能体场景中的自我激励和社会能力。该方法结合了低成本和实时响应性，同时保持智能和目标导向。 这些研究为基于LLM的智能体在模拟人类行为和社会交互方面提供了多种方法和框架。凭借基于LLM的智能体模拟人类沟通和模仿人类思维的能力，这些智能体可以模拟可信的人类行为，参与多方群聊，从模拟环境中学习社会交互，处理记忆和规划任务，并在观点动态中展示人类行为特征。 然而，这些研究也揭示了一些挑战，例如确保基于LLM的智能体在多方群聊中保持轮流发言和对话连贯性，以增强模拟人类行为和社会交互的真实性；以及在模拟环境中有效训练社会对齐的语言模型，以提高基于LLM的智能体在社会交互中的适应性和准确性。此外，基于LLM的智能体必须实现每个人类参与者的多样性和个性化模拟，以更好地反映现实世界的社会现象。未来研究可能会继续探索这些挑战，并提出更有效的方法，以改善基于LLM的智能体在模拟人类行为和社会交互中的性能。5.3.4 法律在法律领域先前的智能体和多智能体系统研究中，Bench-Capon和Sartor[261]利用多智能体模型研究法律推理过程中的理论和价值，提出了法律决策和法律系统设计的新理论和新方法。Branting[262]使用多智能体模型构建了一个计算法律分析模型，研究法律规则和先例在法律推理中的作用。 目前，基于LLM的智能体在法律领域的研究较为有限。Blind Judgement[37]引入了多LLM智能体，用于模拟2010年至2016年间美国最高法院的司法决策，训练了九个独立模型以模仿不同大法官的意见。Shui等人[263]评估了将大型语言模型与专业信息检索系统结合用于案例学习和法律领域问答的有效性。 考虑到基于LLM的智能体具备强大的文本处理和理解能力，以及记录历史案例和决策的记忆机制，它们在法律领域具有巨大的探索潜力，例如以下方面： - 自主法律助手（Autonomous Legal Assistant）：基于LLM的智能体整合法律条款和历史案例审查，为当前案件提供文档撰写和辅助建议。 - 法律决策分析（Legal Decision-making Analysis）：基于LLM的智能体模拟法律决策过程中各个参与者的行为和交互，包括法官、律师和诉讼当事人，以评估不同法律政策和法律系统的优缺点、影响、公平性和效率。 由于法律领域通常涉及大量文本材料，基于LLM的智能体中的大型语言模型需要更长的上下文和更高效的记忆能力。此外，有效表示法律知识（包括法律条款、历史案例和法律原则）并在基于LLM的智能体中执行准确的法律推理，对于做出决策或在阅读和理解法律后进行模拟至关重要。5.3.5 心理学在心理学领域的先前研究中，Sun[264]全面介绍了多智能体交互在认知建模和社会仿真中的应用，涵盖心理学的认知过程、社会交互和情感动机。Marsella和Gratch[265]利用智能体模型模拟情感评估过程，从而更深入地理解情感心理学的基本原理。 目前，基于LLM的智能体主要聚焦于心理健康支持和心理实验仿真方面的应用。Ma等人[266]对基于LLM的智能体支持的心理健康应用进行了定性分析。研究发现，该应用有助于提供按需、无判断的支持，增强用户信心并促进自我发现。然而，它在过滤有害内容、保持一致的沟通、记住新信息以及缓解用户过度依赖方面面临挑战。Aher等人[199]利用基于LLM的智能体模拟心理实验，发现LLM中存在一些“超精确扭曲”，可能影响下游应用。Akata等人[200]使用基于LLM的智能体模拟博弈论中的重复博弈，发现基于LLM的智能体在强调自我利益的游戏中表现尤为出色，特别是在囚徒困境游戏中，表现出优先考虑自我利益而非协调的心理倾向。这些研究为基于LLM的智能体在心理健康支持和心理实验仿真提供了多种方法和框架。这些智能体在提供心理支持、复制心理学发现以及模拟博弈论实验方面具有广泛的应用前景。Humanoid Agents[267]是一个用于开发模拟人类认知、沟通和行为模式的智能体的平台。这些智能体结合了基于特定因素的逻辑推理能力，如满足基本需求、情感以及与他人的交互。Zhang等人[268]研究了基于LLM的多智能体社会反映人类协作智能的潜力。 基于LLM的智能体在心理学领域未来可以探索以下方面： - 心理治疗与咨询（Psychological Therapy and Counseling）：通过模拟心理治疗和咨询过程中的交互和影响，基于LLM的智能体有助于研究人员更深入理解心理治疗和咨询心理学的基本原理，并支持接受心理治疗的患者。 - 认知建模（Cognitive Modeling）：通过模拟感知、记忆、思维和决策等认知过程，基于LLM的智能体为认知心理学核心原理提供见解。具体而言，这些智能体可以通过模拟个体在不同情境下的认知过程，分析认知偏差和策略。 - 情感与动机建模（Emotion and Motivation Modeling）：利用大型语言模型和记忆机制建模情感和动机过程，基于LLM的智能体使研究人员能够通过检查个体的情感反应、兴趣和驱动力，探索情感和动机心理学的基本原理。 然而，这些研究也揭示了一些挑战，例如有效过滤有害内容、保持一致的沟通、实现更拟人化的沟通或仿真，以及解决用户过度依赖问题。未来研究可能会继续探索这些挑战，并提出更有效的方法，以提升基于LLM的智能体在心理健康支持和心理实验仿真中的性能。5.3.6 教育在现有的智能体和多智能体研究中，Woolf[269]介绍了构建智能交互式导师的方法和技术，包括使用智能体和多智能体系统实现个性化教学和自适应学习。Soller和Lesgold[270]提出了利用多智能体模型分析在线知识共享交互的计算方法，以改善教育组织和管理。 凭借其强大的自然语言交互能力，基于LLM的智能体能够与人类高效沟通，这在协助人类学习或模拟课堂方面非常有用。对于研究协助，请参阅研究协助部分。Math Agents[40]将文献中的数学公式转换为LaTeX和Python格式，利用LLM作为语言用户界面和人工智能助手，促进数学与计算机科学之间的交互。AgentVerse[84]是一个基于LLM的多智能体系统框架，模拟自然语言处理课堂教育。CGMI[168]是一个通用的多智能体交互框架，模拟教师与学生之间的各种课堂交互，实验结果表明教学方法、课程和学生表现与真实课堂环境非常相似。此外，基于LLM的智能体可以模拟未来教育政策和系统的实施过程，帮助研究人员评估不同教育策略的优缺点和影响。例如，通过模拟政府、学校、教师和学生的行为，多智能体系统可以预测学术投入、质量和公平性的变化。 在教育领域，基于LLM的智能体面临的主要挑战是输出无害、更可信的内容，以提升教育质量。另一个挑战是多样性和个性化：教育面向多样化的学生群体，实现个性化教学和培训对基于LLM的智能体来说是一个重要问题。5.4 工程系统5.4.1 计算机科学在计算机科学领域的先前智能体和多智能体研究中，Bonabeau[272]探讨了基于智能体的建模方法及其在模拟人类系统中的应用。North和Macal[271]讨论了智能体在商业复杂性管理中的应用。Liu等人[273]提出了多智能体深度强化学习在多级库存管理中的应用。Li等人[274]研究了基于LLM的智能体在任务导向协调中的交互仿真。Lin等人[275]提出了面向决策的对话以促进人机协作。Hasan等人[276]开发了情感虚拟智能体以增强交互体验。 当前基于LLM的智能体在计算机科学中的研究涵盖多个方面： - 计算机操作与人机交互（Computer Operation and Human-computer Interaction）：WebAgent[277]结合专用语言模型和通用语言模型，实现真实网站上的自主导航。WebArena[139]是一个独立的、自托管网络环境，用于构建自主智能体。SheetCopilot[142]通过自然语言促进与电子表格的交互，将复杂请求转化为可执行步骤。 - 网络安全（Network Security）：Rigaki等人[278]提出了一种方法，利用LLM作为攻击智能体，应用于强化学习环境中。 - 代码生成（Code Generation）：GPT-Engineer[43]易于适应和扩展，允许基于LLM的智能体根据提示生成整个代码仓库。Dong等人[68]让多个LLM扮演不同角色，组成一个无需人类干预的团队协作生成代码。ChatDev[66]探索使用LLM驱动的端到端软件开发框架，覆盖需求分析、代码开发、系统测试和文档生成，提供统一、高效、成本效益高的软件开发范式。CAAFE[279]利用LLM生成并执行表格数据集的特征工程代码。AutoGen[83]提出了一个基于提示生成整个代码仓库的自主LLM智能体。 - 软件测试（Software Testing）：LLift[145]是一个与静态分析工具和LLM交互的接口，通过精心设计的智能体和提示实现全自动化。Feldt等人[280]提出了一个自主LLM测试智能体，提供对话框架以帮助开发者的测试，并强调LLM幻觉在测试中的益处。RCAgent[281]是一个增强工具的智能体，用于云环境中实用且注重隐私的工业根本原因分析（RCA）。 - 推荐系统（Recommendation System）：RecAgent[282]使用LLM作为大脑，推荐模型作为工具，创建了一个多功能且交互的推荐系统。Agent4Rec[283]包括用户档案、记忆和行动模块，通过网页交互提供个性化的电影推荐。 - 角色扮演游戏（Role-playing Game）：VOYAGER[50]是一个在Minecraft中由LLM驱动的终身学习智能体，持续探索世界，获取各种技能并发现新事物。GITM[51]提出了一个框架，通过将长期复杂目标转化为最低级的键盘和鼠标操作实现高效灵活的操作。Junprung[284]提出了两个模拟人类行为的智能体：双智能体谈判和六智能体谋杀悬疑游戏。Zhou等人[47]提出了一个对话塑造框架，允许LLM通过对话从非玩家角色（NPCs）获取有用信息并将其转化为知识图，然后使用故事塑造技术加速强化学习智能体收敛到最优策略。Clembench[285]开发了一个灵活且可扩展的框架，使用对话游戏作为测试工具，快速评估多种模型。Tachikuma[286]提出了将虚拟游戏管理员（GMs）集成到智能体的世界模型中，GMs在监督信息、估计玩家意图、提供环境描述、提供反馈和解决当前世界模型局限性方面发挥关键作用。Xu等人[170]在不调整LLM参数的情况下有效进行狼人游戏，并在实验中展示战略行为。MindAgent[181]提出了一个新颖的游戏场景和相关基准，促进多智能体协作效率的评估，并支持同时监督多个参与游戏的智能体。 - 游戏生成（Game Generation）：Chen等人[287]设计了一个基于ChatGPT的文本冒险游戏想象玩法系统，生成与想象玩法相关的故事。GameGPT[288]利用双智能体协作和层次方法，采用多个内部词典自动化游戏开发。 尽管在一些方面取得了成就，基于LLM的智能体在计算机科学中仍有许多研究方向和挑战。例如，在代码生成和测试中，LLM的编码能力至关重要，如何提升基于LLM的智能体的代码质量和测试结果是一个值得关注的问题。在网络安全、推荐系统等方面，充分利用基于LLM的智能体的优势并解决现有问题仍需进一步研究。对于计算机操作和人机交互，基于LLM的智能体必须掌握更多工具使用能力以实现更多功能。此外，通过构建自适应学习和长期发展的基于LLM的智能体系统，它们可以在面对不断变化的计算机科学问题时持续改进性能。 5.4.2 机器人系统在机器人领域先前的智能体和多智能体系统研究中，Parker等人[289]介绍了多移动机器人系统和多机器人间的协作控制问题研究。Busoniu等人[290]讨论了机器人学习和智能相关问题。 在当前的基于LLM的智能体研究中，机器人领域的首要焦点在于机器人任务规划。Di Palo等人[55]提出了一个框架，以语言为核心推理工具，模拟机器人操作环境，并在探索效率和离线数据重用方面展示了显著的性能改进。ProgPrompt[291]提出了一个程序化的LLM提示结构，促进跨各种环境和机器人功能任务的任务规划。Huang等人[292]研究了LLM如何通过自然语言反馈执行机器人控制场景中的推理，而无需进一步训练。TaPA[146]提出了一种在物理场景约束下进行现实世界规划的方法，智能体通过对齐LLM和视觉感知模型生成可执行计划，基于场景中的物体。LLM-Planner[49]利用LLM的力量为具身智能体提供样本高效的规划。Xiang等人[293]通过世界模型微调LLM以获得多样化的具身知识，利用这些经验进一步微调LLM，使其能够在各种物理环境中进行推理和行动。3D-LLM[294]接受3D点云及其特征作为输入，完成一系列与3D相关的任务。ProAgent[71]可以预测队友的即将做出的决策并为其自身制定改进计划，在合作推理中表现出色。此外，它还能动态调整其行为以改善与队友的协作。 基于LLM的智能体在提升自动化水平、支持多场景应用和实现高效任务执行方面具有广阔潜力。未来研究可能会继续解决这些挑战或探索以下方面： - 多机器人协作控制（Multi-robot Collaborative Control）：基于LLM的智能体非常适合模拟多机器人系统中的协作控制和任务分配，帮助研究人员提高此类系统的协作性能和执行效率。例如，通过模拟不同类型机器人、任务和环境的行为和交互，研究人员可以分析多机器人任务分配、路径规划和协作策略。 - 无人机（UAV）集群飞行与控制（Unmanned Aerial Vehicle Swarm Flight and Control）：基于LLM的智能体可以模拟无人机集群飞行中的群体控制、路径规划和避障，帮助研究人员分析无人机集群的飞行稳定性、队形变化和安全飞行。 与此同时，基于LLM的智能体必须更全面地适应和建模复杂环境，因为机器人技术涉及众多复杂环境和任务，需要准确处理复杂问题。此外，机器人必须处理实时多模态数据并做出决策，这意味着智能体还应具备快速响应和多模态处理能力。 5.4.3 电力系统在电力和能源系统领域，已经存在许多基于智能体和多智能体系统的成熟应用。例如，Kilkki等人[295]全面回顾了智能电网中基于智能体的建模和仿真应用，介绍了智能电网的特征和挑战，分类并比较了基于智能体的建模和仿真方法，讨论了其在智能电网不同场景中的应用。Merabet等人[296]回顾了智能电网中的多智能体系统，介绍了多智能体系统的概念和特征，并讨论了其在智能电网中的应用场景、关键技术和挑战。Ghazzali等人[297]研究了使用滑模和多智能体共识设计方法在孤岛微电网中实现固定时间的分布式电压和无功功率补偿。Shinde和Amelin[298]回顾了各种电力市场中基于智能体建模应用的相关文献。May和Huang[299]利用多智能体强化学习在气候变化场景下设计能源市场的动态定价策略。 基于LLM的智能体在电力和能源领域的研究正在发展，相关研究相对较少。未来研究可能探索以下方向： - 智能电网管理与优化（Smart Grid Management and Optimization）：通过模拟发电厂、输电线路和用电设备的行为和交互，基于LLM的智能体可以有效建模智能电网中的挑战。这些挑战包括电力生产、传输、分配和用电管理。还可以评估电网稳定性、能源效率和电力调度。 - 分布式能源调度（Distributed Energy Resource Scheduling）：基于LLM的智能体可以建模分布式能源（如太阳能、风能和储能设备）的调度和优化，研究分布式能源的发电效应、市场竞争和能源互补性。 - 能源市场与交易机制（Energy Market and Trading Mechanisms）：基于LLM的智能体适用于模拟能源市场中的问题，如供需平衡、价格形成和交易机制。具体来说，它们可以模拟能源生产者、消费者和交易平台的行为和交互，分析能源市场的竞争格局、价格波动和交易效率。 在可再生能源和分布式能源资源的大规模集成和协作优化背景下，存在重大挑战。为了实现电力系统的高效运行和可持续发展，基于LLM的智能体必须考虑各种能源类型、多级电网结构和复杂市场环境。此外，制定相关的技术标准和规范对于促进多智能体系统在智能电网中的广泛应用和推广至关重要。这将增强系统的互操作性和可扩展性，同时降低整合的难度和成本。通过广泛的研究和创新，基于LLM的智能体预计将在智能电网管理与优化、分布式能源调度以及能源市场和交易机制中发挥关键作用，最终推动电力系统的可持续发展。5.4.4 交通系统交通领域吸引了智能体系统的广泛研究兴趣。多智能体强化学习（MARL）可用于协调多个交通信号，以优化交通流量、减少拥堵并提高道路交通效率。Zeng等人[300]引入了一种利用深度Q学习的交通信号控制方法。Chu等人[301]将分布式多智能体强化学习技术应用于大规模城市道路网络中的交通信号协调，以减少交通拥堵。 基于LLM的智能体在交通领域的研究目前处于初级阶段。Da等人[302]利用LLM通过基于上下文的提示进行推理，理解和分析系统动态。通过利用LLM的推理能力，可以理解天气条件、交通状况和道路类型如何影响交通动态。随后，智能体根据现实世界的动态采取行动，并据此学习更现实的策略。TrafficGPT[149]将LLM与交通领域专业知识结合，提升交通管理的有效性。此外，它赋予LLM可视化、分析和处理交通数据的能力，为城市交通系统管理提供有价值的决策支持。DiLu[303]集成了推理和反思模块，使自动驾驶系统能够基于常识知识做出决策。 基于LLM的智能体可以在交通领域研究并贡献以下方面：基于LLM的智能体可以管理交通信号，根据实时交通流量和需求优化信号，以减少拥堵和等待时间。相比传统方法，调度员可以通过自然语言调整信号周期。然而，由于涉及多目标优化和决策，这对LLM的推理和决策能力提出了重大挑战。另一方面，基于LLM的智能体可以模拟交通流过程中的车辆行驶和道路条件变化，帮助研究人员理解交通流的特征和影响因素。例如，通过模拟车辆、道路和交通信号的行为和交互，基于LLM的智能体可以分析交通拥堵、事故和效率问题，与原始实现相比提供更高程度的仿真，因为基于LLM的智能体模拟的车辆更接近人类决策。 对于交通系统，通常需要有效处理实时数据并根据实时交通流量和需求优化决策。基于LLM的智能体需要展示快速响应速度。此外，在面对多优化目标和决策因素时，如何高效实施交通信号控制和调度策略仍是一个挑战。 5.4.5 工业控制系统在智能体和多智能体研究领域，Shen和Norrie[304]回顾了当前基于智能体的智能制造系统的研究状况，特别强调了生产调度和资源优化问题。Shen等人[305]全面考察了基于智能体系统在智能制造领域的应用。 目前，基于LLM的智能体在工业控制和工程中的应用包括Xia等人[69]的研究，该研究引入了一个创新框架，整合了大型语言模型、数字孪生和工业自动化系统，用于生产过程的智能规划和控制。作者建立了两种智能体类别：管理智能体，位于自动化模块顶端，负责协调各种模块技能以制定生产计划；操作智能体，位于特定自动化模块内，协调多个功能以执行提供的技能。在节能照明系统中，Nascimento等人[306]利用传感器、执行器和神经网络，通过整合GPT-4实现卓越的决策和适应性，而无需广泛训练。在芯片设计领域，Li等人[307]利用基于LLM的智能体协助开发有限差分时域（FDTD）仿真代码和深度强化学习代码，最终优化了用于高级硅光子和光子集成电路应用的晶体表面发射激光器（PCSEL）结构。 基于LLM的智能体在工业过程控制和优化方面具有广阔潜力，涵盖数据收集仿真、控制策略制定和设备修改等任务。基于LLM的智能体可以通过模拟传感器、控制器和执行器的行为和交互，评估工业过程的稳定性、生产效率和能源消耗。基于LLM的智能体面临的一个挑战是弥合现实世界任务规划与文本任务规划之间的差距，从而增强其在工业过程控制和优化中的实用性。另一个挑战涉及处理工业过程控制和优化中固有的多层次、角色和目标的复杂性及可扩展性问题。5.4.6 医疗系统智能体系统在医疗和制药研究中展示了许多应用，涵盖药物发现与优化、药物机制探索和药代动力学仿真等领域。An[308]展示了基于智能体的计算机仿真在生物医学研究中的应用，包括药物发现和优化过程。Ekins等人[309]提出了用于高通量数据分析的基于智能体的路径映射工具，涉及药物机制研究和药物靶点识别等方面。Walker等人[310]提出了一个基于智能体的细胞社会行为模型，用于模拟个性化药物治疗和精准医学。Singhal等人[311]讨论了在医疗和临床领域增强大型语言模型的方法。Zhavoronkov等人[312]开发了生成张量强化学习（GENTRL），用于设计新型小分子，优化合成化合物的可行性、新颖性和生物活性。 目前，基于LLM的智能体在医疗科学中的研究相对较少。Williams等人[64]引入了一种新的个体模型范式，以解决将人类行为纳入流行病模型的挑战，智能体在流行病期间表现出多波流行模式，与近期流行病中观察到的模式相似。Lobentanzer和Saez-Rodriguez[313]利用通用和生物医学特定知识解决LLM的幻觉问题，并无缝整合常用生物信息学技术，增强其实用性和可靠性。Mehandru等人[314]提出了一个新颖的评估框架，称为“人工智能结构化临床考试”（AI-SCI），用于评估LLM智能体在现实世界临床任务中的性能。 基于LLM的智能体在医疗和制药研究领域具有显著潜力，涵盖以下方面： - 疾病传播与流行病学建模（Disease Transmission and Epidemiological Modeling）：通过模拟疾病传播中各种智能体的行为和交互，包括感染者、易感者和康复者，以及个体移动、社会行为和疾病状态变化等过程，研究人员可以更深入理解疾病传播动态并制定有效的控制策略。 - 药物发现与优化（Drug Discovery and Optimization）：基于LLM的智能体可以用于复制药物发现中的筛选、优化和评估过程，帮助研究人员识别具有特定效果和应用的新型药物。具体来说，通过模拟药物分子、靶标蛋白和生物过程的行为和交互，LLM智能体可以研究药物的结构-活性关系、药效学和药代动力学。 然而，该领域涉及众多高度复杂的生物系统，解决这些复杂性问题并确保模型准确性仍是一个重大挑战。 5.4.7 军事系统智能体和多智能体系统（MAS）在军事研究中具有巨大潜力，特别是在通过仿真和模拟帮助研究人员理解军事问题的复杂性和动态性方面。Ilachinski[315]和Cil及Mala[316]介绍了基于多智能体的战争仿真方法，涵盖战争仿真与战术分析、军事情报和决策支持。Sycara和Sukthankar[317]回顾了团队模型的进展，包括基于多智能体的军事通信和指挥控制系统。 目前，基于LLM的多智能体系统在军事领域的研究有限。未来探索可能集中在以下领域： - 战争仿真与战术分析（War Simulation and Tactical Analysis）：基于LLM的多智能体系统可以用于模拟战争中的作战行动和战术决策。这可能涉及通过多个合作或对立的智能体模拟作战单位、指挥官和地形环境。此类仿真帮助研究人员评估各种战术计划的优缺点，分析作战效能、战场态势和战术优势。  - 军事情报与决策支持（Military Intelligence and Decision Support）：基于LLM的智能体可以用于实现军事情报和决策支持，从而提升指挥决策的准确性和效率。具体来说，智能体可以模拟情报收集、分析和决策过程，实现实时情报分析、预警和战略规划。基于LLM的智能体可以利用其强大的泛化能力，在不同军事场景中进行规划、分析和决策。  然而，军事研究通常需要考虑众多因素，例如确保高度逼真的仿真环境，纳入更准确的战场地形、天气条件、作战单位性能以及多层次（例如战略、作战、战术）和多领域（例如陆、海、空、太空、网络）因素的表征。与人类决策者的有效协作对于准确反映作战行动和战术决策的复杂性和动态性至关重要。同时，必须处理法律和伦理问题。随着人工智能技术在军事中的日益普及，法律和伦理考虑的重要性日益增加。6 讨论6.1 趋势评估（Evaluation） 基于LLM的智能体在特定任务解决、协作和人类交互等多个领域展示了卓越的能力。然而，量化并客观评估其性能仍是一个挑战。 - 基础能力（Foundational Capabilities）：随着基于LLM的智能体研究领域的持续推进，这些智能体的基础能力已达到相对稳定的阶段，这凸显了对这些基础能力进行标准化评估的迫切需求。值得注意的是，Minecraft[50,51,134]和Tachikuma[286]等基准已被引入，用于评估基于LLM的智能体在理解复杂问题和进行逻辑推理方面的能力。此外，AgentSims[143]作为一个多功能框架，用于评估智能体的规划和决策技能，包括其在各种情境下做出明智决策的能力。AgentBench[318]提供了一个综合平台，全面评估智能体的基础能力。对基于LLM的智能体工具和资源利用能力的评估已引起广泛研究关注。随着该领域更标准化和精细调整的评估指标和协议的发展，这一评估预计将进一步演进。特别是ToolBench[196]和Gentopia[163]通过确定智能体如何有效利用各种工具和资源完成任务，为这一评估方面做出了贡献。目前，检索能力在在线购物场景（如WebShop[194]和WebArena[139]）中进行评估。信息检索对于基于LLM的智能体获取更新知识至关重要，应纳入工具使用的基准中。记忆存储、检索和记忆形式机制是基于LLM的智能体维持长期上下文理解和有意义行为的关键设计。Zhong等人[319]讨论了记忆能力的量化指标和精心设计的基准，未来应加入更广泛的任务和指标，以促进基于LLM的智能体更具人性化的记忆行为。  - 基于领域的评估（Domain-based Evaluation）：评估基于LLM的智能体的性能需要对执行环境和特定任务进行基准测试。仅仅依赖MBPP[192]和HumanEval[193]基准是不够的，因为基于LLM的智能体可以观察运行时执行结果并重新生成代码，例如MetaGPT[67]和ChatDev[66]。因此，有必要设计任务级别的定义和评估协议，如AgentBench所示。此外，在法律和医学等多样化领域开发和公布基于任务的基准，对于推动特定领域基于LLM的智能体的研究和应用至关重要。此类基准作为评估这些智能体在专业领域中的效能和能力的关键参考点。同时，在心理学中，基于LLM的智能体情感评估和治疗结果评估等指标依赖于Huang等人[320]报告的人类反馈和比较，数据集和评估机制至关重要。  持续演进（Continual Evolution） 在复杂且动态的环境中操作时，基于LLM的智能体通常需要持续演进，相应调整其参数、记忆和目标。 - 持续学习与自我训练（Continual Learning and Self-training）：基于LLM的智能体的一个关键方面是其持续学习和适应的能力。随着任务和领域的演变，智能体必须在不丢失先前学习信息的情况下获取新知识和技能。终身学习和元学习等技术可以增强智能体的推理能力，使其能够将知识泛化并应用于新情境。此外，有效利用智能体的记忆可以提高其固有的泛化能力。开发有效的持续学习和自我训练机制对于基于LLM的智能体的长期成功和跨领域适用性至关重要。该领域的研究应专注于设计健壮的算法和模型，使智能体能够从多样化的信息源学习，包括文本数据、用户交互和现实世界经验。  - 自我评估与动态目标（Self-Evaluation and Dynamic Goals）：基于LLM的智能体应具备自我评估和目标设定能力，以提升性能并适应变化的环境。智能体能够评估来自环境的反馈并理解对其行为的批评至关重要。基于LLM的智能体可以利用更高效的编程机制从反馈中有效学习并提取和保留关键经验。智能体能够评估信号或定量指标以及定性反馈，增强其处理评估的能力。这种能力涉及评估其优缺点、识别改进领域并设定现实的自我改进目标。智能体还应监控其朝这些目标的进展并进行必要调整以保持正轨。开发自我评估和动态目标设定机制将使基于LLM的智能体更加自主和适应性，从而提升性能并实现更有效的人机协作。- 适应性（Adaptability）：基于LLM的智能体的成功在很大程度上取决于其适应新环境、任务和用户偏好的能力。这种适应性包括理解和调整用户需求、适应不同沟通风格以及快速学习新任务和领域等多个方面。该领域的研究应集中于创建模型和算法，使智能体能够从其经验和与用户的交互中学习，从而调整其行为和策略。开发健壮的大型语言模型和反思技术还将使基于LLM的智能体能够将知识和技能应用于新情境，最终带来更多样化和有效的智能体。  增强多模态能力（Enhancement of Multimodal Capabilities） 在现实世界情境中，智能体必须处理多模态信息，包括图像、视频和语音。整合额外的多模态模型可以为基于LLM的智能体提供多模态能力。这一过程通常涉及将多模态输入转换为文本数据，利用LLM进行推理和规划，并使用多模态模型生成输出。例如，MMReact[321]将ChatGPT与视觉专家池整合，以完成多模态推理和行动。IdealGPT[322]是一个用于视觉推理迭代分解的框架，利用LLM生成子问题，多模态模型提供相应的子答案，LLM推导出最终响应。Di Palo等人[55]处理多模态环境、任务和行动的语言解释。TaPA[146]通过对齐LLM和视觉感知模型，为具有物理场景约束的现实世界场景生成可执行计划。ViperGPT[323]通过代码生成模型结合视觉和语言模型，为任何查询生成结果。 另一方面，近期的大型多模态模型（LMMs），如GPT-4V[324]、miniGPT-v2[325]、LLaVA[326]和PALM-E[327]，展示了对图像内容的强大理解能力。未来在构建基于LMM的智能体时，不再需要先将图像转换为文本再输入LLM。相反，LMM可以直接根据当前图像输入执行多模态任务规划和反思，从而提高信息利用效率和多模态任务处理性能。 6.2 挑战6.2.1 大型语言模型的固有约束大型语言模型为基于LLM的智能体提供了基础，支持规划和反思能力、自然语言表达以及跨多样化任务的强大泛化能力。然而，LLM常常面临上下文长度[14]的限制，可能在处理长篇文章或复杂对话时丢失关键信息。另一个问题是LLM生成无效数据和幻觉[329]。尽管LLM能够生成流畅且看似合理的内容，但它们可能产生无关、无效甚至错误的信息。这种现象源于LLM在训练过程中获取了无关数据或错误模式。这些问题显著影响LLM的效能，进而影响基于LLM的智能体和多智能体系统的整体性能。 6.2.2 动态扩展随着基于LLM的多智能体系统部署的日益广泛，系统必须能够在不同硬件和软件环境中动态扩展，根据需求调整其规模和性能。然而，动态扩展的实施面临几个挑战，包括： - 适应性（Adaptability）：系统必须能够根据不同的任务需求和计算环境调整其规模和性能。这需要强大的适应能力，包括自动调整智能体数量、各种内存空间的大小和转换策略。研究人员可以采用强化学习和遗传算法等自适应算法进行自动优化和调整，以实现这种适应性。  - 资源分配与管理（Resource Allocation and Management）：动态扩展需要为多智能体系统自适应扩展计算和存储资源。在集中式规划分散式执行（CPDE）多智能体系统（见第3.2.2节）中，单一LLM负责角色分配和行动规划，动态扩展必须考虑LLM对数量变化的智能体的分配和规划，以及LLM推理的资源消耗。例如，Yue等人[330]探索构建LLM级联以降低使用LLM的成本，特别是在执行推理任务时。  6.2.3 安全与信任为基于LLM的智能体分配适当权限并确保系统安全至关重要[331]。鉴于这些智能体可以交换信息和资源，过多权限可能导致错误决策和行动，影响整体系统性能并引发安全问题。如何防止有害错误，从而维护人类和企业来之不易的信任？为解决这一问题，开发一个有效的权限分配机制至关重要，该机制应促进不同智能体之间的有效协作，同时不超出其指定权限。此外，进行可靠性测试的重要性不容忽视。例如，ToolEmu[332]利用LLM模拟工具执行，展示了其在各种工具和场景中评估基于LLM的智能体的能力。这种方法能够检测智能体故障并量化相关风险。7 结论在本文中，我们全面探讨了基于大型语言模型的智能体（LLM-based Agents），包括单智能体系统和多智能体系统，涵盖其定义、方法论和未来发展前景。我们首先回顾了智能体的概念及其在人工智能中的重要性，强调了基于强化学习的智能体和基于LLM的智能体之间的区别。随后，我们详细分析了基于LLM的单智能体系统的框架，包括规划、记忆、反思、环境和行动等关键组件，并进一步探讨了基于LLM的多智能体系统的关系、规划类型和通信效率提升策略。此外，我们介绍了用于评估基于LLM的智能体性能的常见数据集和基准，并讨论了其在自然科学、社会科学、工程系统和通用任务助手等领域的潜在应用前景。 基于LLM的智能体展示了强大的语言理解、推理能力和任务泛化能力，使其在多样化场景中具有广泛的应用潜力。然而，我们也指出了当前研究的局限性，包括大型语言模型的固有约束（如上下文长度限制和幻觉问题）、动态扩展的挑战以及安全与信任问题。未来研究应专注于解决这些挑战，同时推动基于LLM的智能体在评估标准、持续演进和多模态能力方面的进步。 展望未来，随着大型语言模型和人工智能技术的不断发展，基于LLM的智能体有望在从科学研究到日常任务协助的各个领域发挥更大作用。通过整合多模态数据、增强适应性和可靠性，这些智能体可能成为迈向通用人工智能（AGI）的重要一步，为人类社会带来深远的变革。



Coscientist[218]利用大型语言模型的功能，结合互联网和文献搜索、代码执行和实验自动化等工具，能够自主设计、规划和执行现实世界的化学实验。


图2：基于LLM的智能体概览

输入：目标（O）和环境观察输入到LLM（L）。
处理：LLM结合记忆（M）进行规划，生成行动（A）。
执行：行动作用于环境或调用工具，产生结果。
反馈：环境返回反馈，智能体通过反思（R）更新记忆并优化后续行动。
循环：流程重复，直到目标达成。


机器人领域

在当前的基于LLM的智能体研究中，机器人领域的首要焦点在于机器人任务规划。
Di Palo等人[55]提出了一个框架，以语言为核心推理工具，模拟机器人操作环境，并在探索效率和离线数据重用方面展示了显著的性能改进。
ProgPrompt[291]提出了一个程序化的LLM提示结构，促进跨各种环境和机器人功能任务的任务规划。
Huang等人[292]研究了LLM如何通过自然语言反馈执行机器人控制场景中的推理，而无需进一步训练。
TaPA[146]提出了一种在物理场景约束下进行现实世界规划的方法，智能体通过对齐LLM和视觉感知模型生成可执行计划，基于场景中的物体。
LLM-Planner[49]利用LLM的力量为具身智能体提供样本高效的规划。
Xiang等人[293]通过世界模型微调LLM以获得多样化的具身知识，利用这些经验进一步微调LLM，使其能够在各种物理环境中进行推理和行动。
3D-LLM[294]接受3D点云及其特征作为输入，完成一系列与3D相关的任务。
ProAgent[71]可以预测队友的即将做出的决策并为其自身制定改进计划，在合作推理中表现出色。此外，它还能动态调整其行为以改善与队友的协作。 

ProgPrompt: Generating Situated Robot Task Plans using Large Language Models
https://progprompt.github.io/




VLM 
https://github.com/OpenGVLab/vinci  

dify

tool use 

AutoGen

collect all projects and find similarity 